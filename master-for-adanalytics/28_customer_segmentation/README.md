# 28. Customer Segmentation - ê³ ê° ì„¸ë¶„í™”

## ğŸ“š ê³¼ì • ì†Œê°œ
ë¨¸ì‹ ëŸ¬ë‹ì„ í™œìš©í•œ ê³ ê° ì„¸ë¶„í™”ì™€ ê°œì¸í™” ë§ˆì¼€íŒ… ì „ëµì„ ë§ˆìŠ¤í„°í•©ë‹ˆë‹¤. RFM ë¶„ì„ë¶€í„° ê³ ê¸‰ í´ëŸ¬ìŠ¤í„°ë§ê¹Œì§€ ì‹¤ë¬´ì— ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ê¸°ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- RFM ê¸°ë°˜ ê³ ê° ì„¸ë¶„í™”
- í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜ í™œìš©
- ê°œì¸í™” ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½
- ê³ ê° ìƒì•  ê°€ì¹˜(LTV) ì˜ˆì¸¡

## ğŸ“– ì£¼ìš” ë‚´ìš©

### RFM ë¶„ì„ êµ¬í˜„
```python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from typing import Dict, List, Tuple
import plotly.express as px
import plotly.graph_objects as go

class RFMAnalyzer:
    """RFM ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.rfm_data = None
        self.segments = None
        
    def calculate_rfm(self, transactions_df: pd.DataFrame, 
                     customer_col: str = 'customer_id',
                     date_col: str = 'order_date', 
                     amount_col: str = 'amount',
                     analysis_date: datetime = None) -> pd.DataFrame:
        """RFM ê°’ ê³„ì‚°"""
        
        if analysis_date is None:
            analysis_date = transactions_df[date_col].max()
        
        # Recency: ë§ˆì§€ë§‰ êµ¬ë§¤ ì´í›„ ê²½ê³¼ ì¼ìˆ˜
        recency = transactions_df.groupby(customer_col)[date_col].max().reset_index()
        recency['recency'] = (analysis_date - recency[date_col]).dt.days
        
        # Frequency: êµ¬ë§¤ ë¹ˆë„
        frequency = transactions_df.groupby(customer_col)[date_col].count().reset_index()
        frequency.columns = [customer_col, 'frequency']
        
        # Monetary: ì´ êµ¬ë§¤ ê¸ˆì•¡
        monetary = transactions_df.groupby(customer_col)[amount_col].sum().reset_index()
        monetary.columns = [customer_col, 'monetary']
        
        # RFM ë°ì´í„° ë³‘í•©
        rfm = recency[[customer_col, 'recency']].merge(
            frequency, on=customer_col
        ).merge(monetary, on=customer_col)
        
        # RFM ì ìˆ˜ ê³„ì‚° (1-5 ìŠ¤ì¼€ì¼)
        rfm['r_score'] = pd.qcut(rfm['recency'].rank(method='first'), 5, labels=[5,4,3,2,1])
        rfm['f_score'] = pd.qcut(rfm['frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])
        rfm['m_score'] = pd.qcut(rfm['monetary'].rank(method='first'), 5, labels=[1,2,3,4,5])
        
        # RFM í†µí•© ì ìˆ˜
        rfm['rfm_score'] = rfm['r_score'].astype(str) + rfm['f_score'].astype(str) + rfm['m_score'].astype(str)
        
        self.rfm_data = rfm
        return rfm
    
    def segment_customers(self, rfm_df: pd.DataFrame = None) -> pd.DataFrame:
        """ê³ ê° ì„¸ë¶„í™”"""
        if rfm_df is None:
            rfm_df = self.rfm_data
        
        # ì„¸ë¶„í™” ê·œì¹™ ì •ì˜
        def assign_segment(row):
            r, f, m = int(row['r_score']), int(row['f_score']), int(row['m_score'])
            
            # Champions: ìµœê³  ê³ ê°
            if r >= 4 and f >= 4 and m >= 4:
                return 'Champions'
            
            # Loyal Customers: ì¶©ì„± ê³ ê°
            elif r >= 3 and f >= 3 and m >= 3:
                return 'Loyal Customers'
            
            # Potential Loyalists: ì ì¬ ì¶©ì„± ê³ ê°
            elif r >= 3 and f >= 2 and m >= 2:
                return 'Potential Loyalists'
            
            # New Customers: ì‹ ê·œ ê³ ê° (ë†’ì€ Recency, ë‚®ì€ Frequency)
            elif r >= 4 and f <= 2:
                return 'New Customers'
            
            # Promising: ìœ ë§ ê³ ê°
            elif r >= 3 and f >= 2 and m <= 2:
                return 'Promising'
            
            # Need Attention: ê´€ì‹¬ í•„ìš”
            elif r >= 3 and f <= 2 and m <= 2:
                return 'Need Attention'
            
            # About to Sleep: ì ë“¤ ìœ„í—˜
            elif r == 2 and f >= 2:
                return 'About to Sleep'
            
            # At Risk: ìœ„í—˜ ê³ ê°
            elif r <= 2 and f >= 3 and m >= 3:
                return 'At Risk'
            
            # Cannot Lose Them: ìƒìœ¼ë©´ ì•ˆ ë˜ëŠ” ê³ ê°
            elif r <= 2 and f >= 4 and m >= 4:
                return 'Cannot Lose Them'
            
            # Hibernating: íœ´ë©´ ê³ ê°
            elif r <= 2 and f <= 2 and m >= 2:
                return 'Hibernating'
            
            # Lost: ì´íƒˆ ê³ ê°
            else:
                return 'Lost'
        
        rfm_df['segment'] = rfm_df.apply(assign_segment, axis=1)
        self.segments = rfm_df
        return rfm_df
    
    def get_segment_analysis(self) -> Dict:
        """ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„"""
        if self.segments is None:
            raise ValueError("ë¨¼ì € segment_customers()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        
        segment_analysis = self.segments.groupby('segment').agg({
            'customer_id': 'count',
            'recency': 'mean',
            'frequency': 'mean', 
            'monetary': 'mean'
        }).round(2)
        
        segment_analysis.columns = ['customer_count', 'avg_recency', 'avg_frequency', 'avg_monetary']
        segment_analysis['percentage'] = (segment_analysis['customer_count'] / 
                                        segment_analysis['customer_count'].sum() * 100).round(2)
        
        return segment_analysis.to_dict('index')
    
    def visualize_rfm_distribution(self):
        """RFM ë¶„í¬ ì‹œê°í™”"""
        if self.rfm_data is None:
            raise ValueError("ë¨¼ì € calculate_rfm()ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # Recency ë¶„í¬
        axes[0,0].hist(self.rfm_data['recency'], bins=50, alpha=0.7, color='skyblue')
        axes[0,0].set_title('Recency Distribution')
        axes[0,0].set_xlabel('Days Since Last Purchase')
        axes[0,0].set_ylabel('Number of Customers')
        
        # Frequency ë¶„í¬
        axes[0,1].hist(self.rfm_data['frequency'], bins=50, alpha=0.7, color='lightgreen')
        axes[0,1].set_title('Frequency Distribution')
        axes[0,1].set_xlabel('Number of Purchases')
        axes[0,1].set_ylabel('Number of Customers')
        
        # Monetary ë¶„í¬
        axes[1,0].hist(self.rfm_data['monetary'], bins=50, alpha=0.7, color='salmon')
        axes[1,0].set_title('Monetary Distribution')
        axes[1,0].set_xlabel('Total Purchase Amount')
        axes[1,0].set_ylabel('Number of Customers')
        
        # RFM ìƒê´€ê´€ê³„
        correlation_data = self.rfm_data[['recency', 'frequency', 'monetary']].corr()
        sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0, ax=axes[1,1])
        axes[1,1].set_title('RFM Correlation Matrix')
        
        plt.tight_layout()
        plt.show()
    
    def create_rfm_3d_plot(self):
        """3D RFM ì‹œê°í™”"""
        if self.segments is None:
            raise ValueError("ë¨¼ì € segment_customers()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        
        fig = go.Figure(data=[go.Scatter3d(
            x=self.segments['recency'],
            y=self.segments['frequency'], 
            z=self.segments['monetary'],
            mode='markers',
            marker=dict(
                size=5,
                color=self.segments['segment'].astype('category').cat.codes,
                colorscale='Viridis',
                showscale=True
            ),
            text=self.segments['segment'],
            hovertemplate='<b>%{text}</b><br>' +
                         'Recency: %{x}<br>' +
                         'Frequency: %{y}<br>' +
                         'Monetary: %{z}<br>' +
                         '<extra></extra>'
        )])
        
        fig.update_layout(
            title='3D RFM Customer Segmentation',
            scene=dict(
                xaxis_title='Recency (Days)',
                yaxis_title='Frequency (Count)',
                zaxis_title='Monetary (Amount)'
            ),
            height=700
        )
        
        return fig

class AdvancedSegmentation:
    """ê³ ê¸‰ ì„¸ë¶„í™” ê¸°ë²•"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.kmeans = None
        self.features = None
        
    def prepare_features(self, customer_df: pd.DataFrame) -> pd.DataFrame:
        """íŠ¹ì„± ì¤€ë¹„"""
        features = customer_df.copy()
        
        # íŒŒìƒ ë³€ìˆ˜ ìƒì„±
        features['avg_order_value'] = features['monetary'] / features['frequency']
        features['recency_log'] = np.log1p(features['recency'])
        features['monetary_log'] = np.log1p(features['monetary'])
        
        # ê³„ì ˆì„± íŠ¹ì„± (ë§ˆì§€ë§‰ êµ¬ë§¤ ì›”)
        if 'last_purchase_date' in features.columns:
            features['last_purchase_month'] = pd.to_datetime(features['last_purchase_date']).dt.month
            features['last_purchase_quarter'] = pd.to_datetime(features['last_purchase_date']).dt.quarter
        
        # êµ¬ë§¤ íŒ¨í„´ íŠ¹ì„±
        features['purchase_consistency'] = features['frequency'] / (features['recency'] / 30 + 1)
        
        return features
    
    def find_optimal_clusters(self, features_df: pd.DataFrame, 
                            max_clusters: int = 10) -> Dict:
        """ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸°"""
        # ìˆ˜ì¹˜í˜• íŠ¹ì„±ë§Œ ì„ íƒ
        numeric_features = features_df.select_dtypes(include=[np.number])
        
        # í‘œì¤€í™”
        scaled_features = self.scaler.fit_transform(numeric_features)
        
        # Elbow Method
        inertias = []
        silhouette_scores = []
        
        from sklearn.metrics import silhouette_score
        
        K_range = range(2, max_clusters + 1)
        
        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            kmeans.fit(scaled_features)
            
            inertias.append(kmeans.inertia_)
            silhouette_scores.append(silhouette_score(scaled_features, kmeans.labels_))
        
        # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì¶”ì²œ (ì‹¤ë£¨ì—£ ì ìˆ˜ ê¸°ì¤€)
        optimal_k = K_range[np.argmax(silhouette_scores)]
        
        return {
            'k_range': list(K_range),
            'inertias': inertias,
            'silhouette_scores': silhouette_scores,
            'optimal_k': optimal_k
        }
    
    def perform_clustering(self, features_df: pd.DataFrame, 
                         n_clusters: int = None) -> pd.DataFrame:
        """K-means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰"""
        # ìˆ˜ì¹˜í˜• íŠ¹ì„±ë§Œ ì„ íƒ
        numeric_features = features_df.select_dtypes(include=[np.number])
        self.features = numeric_features.columns.tolist()
        
        # í‘œì¤€í™”
        scaled_features = self.scaler.fit_transform(numeric_features)
        
        # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ìë™ ê²°ì •
        if n_clusters is None:
            cluster_analysis = self.find_optimal_clusters(features_df)
            n_clusters = cluster_analysis['optimal_k']
        
        # K-means í´ëŸ¬ìŠ¤í„°ë§
        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        clusters = self.kmeans.fit_predict(scaled_features)
        
        # ê²°ê³¼ DataFrame ìƒì„±
        result_df = features_df.copy()
        result_df['cluster'] = clusters
        
        return result_df
    
    def analyze_clusters(self, clustered_df: pd.DataFrame) -> Dict:
        """í´ëŸ¬ìŠ¤í„° ë¶„ì„"""
        cluster_analysis = {}
        
        for cluster_id in sorted(clustered_df['cluster'].unique()):
            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]
            
            # ê¸°ë³¸ í†µê³„
            stats = {}
            for feature in self.features:
                if feature in cluster_data.columns:
                    stats[feature] = {
                        'mean': cluster_data[feature].mean(),
                        'median': cluster_data[feature].median(),
                        'std': cluster_data[feature].std()
                    }
            
            cluster_analysis[f'Cluster_{cluster_id}'] = {
                'size': len(cluster_data),
                'percentage': len(cluster_data) / len(clustered_df) * 100,
                'statistics': stats
            }
        
        return cluster_analysis
    
    def create_cluster_profiles(self, clustered_df: pd.DataFrame) -> Dict:
        """í´ëŸ¬ìŠ¤í„° í”„ë¡œí•„ ìƒì„±"""
        profiles = {}
        
        cluster_means = clustered_df.groupby('cluster')[self.features].mean()
        overall_means = clustered_df[self.features].mean()
        
        for cluster_id in sorted(clustered_df['cluster'].unique()):
            cluster_mean = cluster_means.loc[cluster_id]
            
            # ì „ì²´ í‰ê·  ëŒ€ë¹„ ì°¨ì´ ê³„ì‚°
            profile = {}
            for feature in self.features:
                ratio = cluster_mean[feature] / overall_means[feature]
                
                if ratio > 1.5:
                    profile[feature] = 'Very High'
                elif ratio > 1.2:
                    profile[feature] = 'High'
                elif ratio > 0.8:
                    profile[feature] = 'Average'
                elif ratio > 0.5:
                    profile[feature] = 'Low'
                else:
                    profile[feature] = 'Very Low'
            
            # í´ëŸ¬ìŠ¤í„° íŠ¹ì„±í™”
            if profile.get('monetary', 'Average') in ['High', 'Very High'] and \
               profile.get('frequency', 'Average') in ['High', 'Very High']:
                cluster_name = 'VIP Customers'
            elif profile.get('recency', 'Average') in ['Very Low', 'Low']:
                cluster_name = 'Active Customers'
            elif profile.get('recency', 'Average') in ['High', 'Very High']:
                cluster_name = 'Inactive Customers'
            elif profile.get('frequency', 'Average') == 'Very Low':
                cluster_name = 'One-time Customers'
            else:
                cluster_name = f'Cluster_{cluster_id}'
            
            profiles[cluster_name] = {
                'cluster_id': cluster_id,
                'profile': profile,
                'size': len(clustered_df[clustered_df['cluster'] == cluster_id])
            }
        
        return profiles

class CustomerLifetimeValue:
    """ê³ ê° ìƒì•  ê°€ì¹˜ ì˜ˆì¸¡"""
    
    def __init__(self):
        self.model = None
        
    def calculate_historical_ltv(self, transactions_df: pd.DataFrame,
                               customer_col: str = 'customer_id',
                               date_col: str = 'order_date',
                               amount_col: str = 'amount') -> pd.DataFrame:
        """ê³¼ê±° LTV ê³„ì‚°"""
        
        # ê³ ê°ë³„ ì§‘ê³„
        customer_summary = transactions_df.groupby(customer_col).agg({
            amount_col: ['sum', 'mean', 'count'],
            date_col: ['min', 'max']
        }).round(2)
        
        customer_summary.columns = ['total_revenue', 'avg_order_value', 'frequency', 
                                  'first_purchase', 'last_purchase']
        
        # ê³ ê° ìƒì•  ê¸°ê°„ ê³„ì‚° (ì¼)
        customer_summary['lifespan_days'] = (
            customer_summary['last_purchase'] - customer_summary['first_purchase']
        ).dt.days + 1
        
        # êµ¬ë§¤ ì£¼ê¸° ê³„ì‚°
        customer_summary['avg_days_between_purchases'] = (
            customer_summary['lifespan_days'] / customer_summary['frequency']
        )
        
        # Historical LTV
        customer_summary['historical_ltv'] = customer_summary['total_revenue']
        
        return customer_summary.reset_index()
    
    def predict_future_ltv(self, customer_summary: pd.DataFrame,
                          prediction_period_days: int = 365) -> pd.DataFrame:
        """ë¯¸ë˜ LTV ì˜ˆì¸¡"""
        
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ëª¨ë¸
        def predict_ltv(row):
            if row['frequency'] <= 1:
                # ì¼íšŒì„± ê³ ê°
                return row['avg_order_value'] * 0.1
            
            # í‰ê·  êµ¬ë§¤ ì£¼ê¸°ë¡œ ì˜ˆì¸¡ ê¸°ê°„ ë‚´ ì˜ˆìƒ êµ¬ë§¤ íšŸìˆ˜ ê³„ì‚°
            if row['avg_days_between_purchases'] > 0:
                predicted_purchases = prediction_period_days / row['avg_days_between_purchases']
                
                # ì´íƒˆë¥  ê³ ë ¤ (ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ êµ¬ë§¤ í™•ë¥  ê°ì†Œ)
                decay_factor = np.exp(-prediction_period_days / 365)  # 1ë…„ ê¸°ì¤€ ê°ì‡ 
                predicted_purchases *= decay_factor
                
                return row['avg_order_value'] * predicted_purchases
            
            return 0
        
        customer_summary['predicted_ltv'] = customer_summary.apply(predict_ltv, axis=1)
        customer_summary['total_predicted_ltv'] = (
            customer_summary['historical_ltv'] + customer_summary['predicted_ltv']
        )
        
        return customer_summary
    
    def segment_by_ltv(self, customer_ltv: pd.DataFrame) -> pd.DataFrame:
        """LTV ê¸°ë°˜ ì„¸ë¶„í™”"""
        
        # LTV ë¶„ìœ„ìˆ˜ ê³„ì‚°
        customer_ltv['ltv_quartile'] = pd.qcut(
            customer_ltv['total_predicted_ltv'], 
            q=4, 
            labels=['Low Value', 'Medium Value', 'High Value', 'Top Value']
        )
        
        # LTV ì„¸ê·¸ë¨¼íŠ¸ë³„ íŠ¹ì„±
        ltv_segments = customer_ltv.groupby('ltv_quartile').agg({
            'customer_id': 'count',
            'total_predicted_ltv': ['mean', 'median', 'sum'],
            'frequency': 'mean',
            'avg_order_value': 'mean'
        }).round(2)
        
        return customer_ltv, ltv_segments

class PersonalizationEngine:
    """ê°œì¸í™” ì—”ì§„"""
    
    def __init__(self):
        self.segment_strategies = {
            'Champions': {
                'message': 'í”„ë¦¬ë¯¸ì—„ ê³ ê° ì „ìš© í˜œíƒì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤',
                'channel': ['email', 'sms', 'push'],
                'frequency': 'weekly',
                'discount': 0,
                'product_recommendation': 'premium'
            },
            'Loyal Customers': {
                'message': 'ì¶©ì„± ê³ ê°ë‹˜ì„ ìœ„í•œ íŠ¹ë³„ í• ì¸',
                'channel': ['email', 'push'],
                'frequency': 'bi-weekly',
                'discount': 10,
                'product_recommendation': 'cross_sell'
            },
            'Potential Loyalists': {
                'message': 'íšŒì› ë“±ê¸‰ ì—…ê·¸ë ˆì´ë“œ ê¸°íšŒ!',
                'channel': ['email'],
                'frequency': 'monthly',
                'discount': 15,
                'product_recommendation': 'up_sell'
            },
            'At Risk': {
                'message': 'ëŒì•„ì˜¤ì„¸ìš”! íŠ¹ë³„ í˜œíƒì„ ë“œë¦½ë‹ˆë‹¤',
                'channel': ['email', 'sms'],
                'frequency': 'weekly',
                'discount': 20,
                'product_recommendation': 'win_back'
            },
            'Lost': {
                'message': 'ê·¸ë™ì•ˆ ê°ì‚¬í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ê¸°íšŒë¥¼ ë“œë¦½ë‹ˆë‹¤',
                'channel': ['email'],
                'frequency': 'monthly',
                'discount': 25,
                'product_recommendation': 'reactivation'
            }
        }
    
    def generate_campaign_strategy(self, segment_analysis: Dict) -> Dict:
        """ì„¸ê·¸ë¨¼íŠ¸ë³„ ìº í˜ì¸ ì „ëµ ìƒì„±"""
        campaign_strategies = {}
        
        for segment, data in segment_analysis.items():
            if segment in self.segment_strategies:
                strategy = self.segment_strategies[segment].copy()
                strategy['segment_size'] = data['customer_count']
                strategy['expected_response_rate'] = self._estimate_response_rate(segment)
                strategy['priority'] = self._calculate_priority(segment, data)
                
                campaign_strategies[segment] = strategy
        
        return campaign_strategies
    
    def _estimate_response_rate(self, segment: str) -> float:
        """ì„¸ê·¸ë¨¼íŠ¸ë³„ ì˜ˆìƒ ë°˜ì‘ë¥ """
        response_rates = {
            'Champions': 0.25,
            'Loyal Customers': 0.20,
            'Potential Loyalists': 0.15,
            'New Customers': 0.12,
            'At Risk': 0.08,
            'Lost': 0.03
        }
        return response_rates.get(segment, 0.10)
    
    def _calculate_priority(self, segment: str, data: Dict) -> int:
        """ì„¸ê·¸ë¨¼íŠ¸ ìš°ì„ ìˆœìœ„ ê³„ì‚°"""
        priority_weights = {
            'Champions': 10,
            'Cannot Lose Them': 9,
            'At Risk': 8,
            'Loyal Customers': 7,
            'Potential Loyalists': 6,
            'Need Attention': 5,
            'About to Sleep': 4,
            'New Customers': 3,
            'Promising': 2,
            'Lost': 1
        }
        
        base_priority = priority_weights.get(segment, 5)
        # ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸°ì— ë”°ë¥¸ ì¡°ì •
        size_factor = min(data['customer_count'] / 1000, 2)  # ìµœëŒ€ 2ë°°
        
        return int(base_priority * (1 + size_factor))

# ì‚¬ìš© ì˜ˆì‹œ
def example_customer_segmentation():
    """ê³ ê° ì„¸ë¶„í™” ì˜ˆì‹œ"""
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    
    # ê±°ë˜ ë°ì´í„° ìƒì„±
    customers = [f'C{i:05d}' for i in range(1, 1001)]
    transactions = []
    
    for customer in customers:
        # ê³ ê°ë³„ ê±°ë˜ íŒ¨í„´ ìƒì„±
        n_transactions = np.random.poisson(5) + 1
        first_date = pd.Timestamp('2023-01-01') + pd.Timedelta(days=np.random.randint(0, 200))
        
        for i in range(n_transactions):
            transaction_date = first_date + pd.Timedelta(days=np.random.randint(0, 300))
            amount = np.random.lognormal(4, 1)  # í‰ê·  ì•½ 54, ë‹¤ì–‘í•œ ë¶„í¬
            
            transactions.append({
                'customer_id': customer,
                'order_date': transaction_date,
                'amount': amount
            })
    
    transactions_df = pd.DataFrame(transactions)
    
    # RFM ë¶„ì„ ì‹¤í–‰
    rfm_analyzer = RFMAnalyzer()
    rfm_data = rfm_analyzer.calculate_rfm(transactions_df)
    segmented_data = rfm_analyzer.segment_customers()
    segment_analysis = rfm_analyzer.get_segment_analysis()
    
    # ê³ ê¸‰ ì„¸ë¶„í™”
    advanced_seg = AdvancedSegmentation()
    clustered_data = advanced_seg.perform_clustering(rfm_data, n_clusters=5)
    cluster_profiles = advanced_seg.create_cluster_profiles(clustered_data)
    
    # LTV ë¶„ì„
    ltv_analyzer = CustomerLifetimeValue()
    customer_summary = ltv_analyzer.calculate_historical_ltv(transactions_df)
    customer_ltv = ltv_analyzer.predict_future_ltv(customer_summary)
    
    # ê°œì¸í™” ì „ëµ
    personalization = PersonalizationEngine()
    campaign_strategies = personalization.generate_campaign_strategy(segment_analysis)
    
    return {
        'rfm_analysis': segment_analysis,
        'cluster_profiles': cluster_profiles,
        'ltv_segments': customer_ltv.head(10),
        'campaign_strategies': campaign_strategies
    }

if __name__ == "__main__":
    results = example_customer_segmentation()
    print("ê³ ê° ì„¸ë¶„í™” ë¶„ì„ ì™„ë£Œ!")
```

## ğŸš€ í”„ë¡œì íŠ¸
1. **RFM ê¸°ë°˜ ê³ ê° ì„¸ë¶„í™” ì‹œìŠ¤í…œ**
2. **ë¨¸ì‹ ëŸ¬ë‹ í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë¸**
3. **ê³ ê° ìƒì•  ê°€ì¹˜ ì˜ˆì¸¡ ì—”ì§„**
4. **ê°œì¸í™” ë§ˆì¼€íŒ… ìº í˜ì¸ í”Œë«í¼**