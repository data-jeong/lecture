"""
ìŠ¤ë ˆë“œ ê¸°ë°˜ íŒŒì¼ ì²˜ë¦¬ê¸°
threadingê³¼ concurrent.futuresë¥¼ í™œìš©í•œ íŒŒì¼ ì²˜ë¦¬
"""

import threading
import concurrent.futures
from pathlib import Path
from typing import List, Dict, Optional, Callable, Any
from dataclasses import dataclass
import time
import queue
import hashlib
from threading import Lock, Event
import json


@dataclass 
class ThreadResult:
    """ìŠ¤ë ˆë“œ ì²˜ë¦¬ ê²°ê³¼"""
    thread_id: int
    file_path: str
    success: bool
    result: Any = None
    error: Optional[str] = None
    duration: float = 0.0


class ThreadProcessor:
    """ìŠ¤ë ˆë“œ ê¸°ë°˜ íŒŒì¼ ì²˜ë¦¬ê¸°"""
    
    def __init__(self, max_workers: int = 10):
        self.max_workers = max_workers
        self.results: List[ThreadResult] = []
        self.results_lock = Lock()
        self.task_queue = queue.Queue()
        self.stop_event = Event()
        self.active_threads = 0
        self.active_threads_lock = Lock()
    
    def process_file(self, file_path: str, processor: Callable[[str], Any]) -> ThreadResult:
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬"""
        thread_id = threading.get_ident()
        start_time = time.perf_counter()
        
        try:
            # íŒŒì¼ ì½ê¸°
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ì²˜ë¦¬
            result = processor(content)
            
            duration = time.perf_counter() - start_time
            
            return ThreadResult(
                thread_id=thread_id,
                file_path=file_path,
                success=True,
                result=result,
                duration=duration
            )
            
        except Exception as e:
            duration = time.perf_counter() - start_time
            return ThreadResult(
                thread_id=thread_id,
                file_path=file_path,
                success=False,
                error=str(e),
                duration=duration
            )
    
    def worker(self, processor: Callable[[str], Any]):
        """ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        with self.active_threads_lock:
            self.active_threads += 1
        
        try:
            while not self.stop_event.is_set():
                try:
                    file_path = self.task_queue.get(timeout=0.1)
                    
                    # íŒŒì¼ ì²˜ë¦¬
                    result = self.process_file(file_path, processor)
                    
                    # ê²°ê³¼ ì €ì¥
                    with self.results_lock:
                        self.results.append(result)
                    
                    self.task_queue.task_done()
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    print(f"Worker error: {e}")
                    
        finally:
            with self.active_threads_lock:
                self.active_threads -= 1
    
    def process_directory_threaded(
        self,
        directory: str,
        pattern: str = "*",
        processor: Callable[[str], Any] = None,
        recursive: bool = True
    ) -> List[ThreadResult]:
        """ìŠ¤ë ˆë“œë¥¼ ì‚¬ìš©í•œ ë””ë ‰í† ë¦¬ ì²˜ë¦¬"""
        path = Path(directory)
        
        if recursive:
            files = list(path.rglob(pattern))
        else:
            files = list(path.glob(pattern))
        
        # íŒŒì¼ë§Œ í•„í„°ë§
        files = [f for f in files if f.is_file()]
        print(f"ğŸ“ {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
        
        if processor is None:
            processor = self._default_processor
        
        # ì‘ì—… íì— íŒŒì¼ ì¶”ê°€
        for file_path in files:
            self.task_queue.put(str(file_path))
        
        # ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
        threads = []
        for i in range(min(self.max_workers, len(files))):
            t = threading.Thread(target=self.worker, args=(processor,))
            t.start()
            threads.append(t)
        
        # ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
        total_files = len(files)
        while not self.task_queue.empty() or self.active_threads > 0:
            processed = len(self.results)
            remaining = self.task_queue.qsize()
            
            print(f"\rì§„í–‰: {processed}/{total_files} | "
                  f"ëŒ€ê¸°: {remaining} | "
                  f"í™œì„± ìŠ¤ë ˆë“œ: {self.active_threads}", end='')
            
            time.sleep(0.1)
        
        # ìŠ¤ë ˆë“œ ì¢…ë£Œ
        self.stop_event.set()
        for t in threads:
            t.join()
        
        print()  # ì¤„ë°”ê¿ˆ
        return self.results
    
    def process_directory_pool(
        self,
        directory: str,
        pattern: str = "*",
        processor: Callable[[str], Any] = None,
        recursive: bool = True
    ) -> List[ThreadResult]:
        """ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë””ë ‰í† ë¦¬ ì²˜ë¦¬"""
        path = Path(directory)
        
        if recursive:
            files = list(path.rglob(pattern))
        else:
            files = list(path.glob(pattern))
        
        # íŒŒì¼ë§Œ í•„í„°ë§
        files = [f for f in files if f.is_file()]
        print(f"ğŸ“ {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
        
        if processor is None:
            processor = self._default_processor
        
        results = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # ì‘ì—… ì œì¶œ
            future_to_file = {
                executor.submit(self.process_file, str(f), processor): f
                for f in files
            }
            
            # ì™„ë£Œëœ ì‘ì—… ì²˜ë¦¬
            completed = 0
            for future in concurrent.futures.as_completed(future_to_file):
                completed += 1
                result = future.result()
                results.append(result)
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                success_count = sum(1 for r in results if r.success)
                print(f"\rì§„í–‰: {completed}/{len(files)} | "
                      f"ì„±ê³µ: {success_count} | "
                      f"ì‹¤íŒ¨: {completed - success_count}", end='')
        
        print()  # ì¤„ë°”ê¿ˆ
        self.results.extend(results)
        return results
    
    def _default_processor(self, content: str) -> dict:
        """ê¸°ë³¸ ì²˜ë¦¬ê¸°"""
        return {
            "size": len(content),
            "lines": content.count('\n'),
            "words": len(content.split()),
            "hash": hashlib.md5(content.encode()).hexdigest()
        }
    
    def parallel_map_threaded(
        self,
        func: Callable[[Any], Any],
        items: List[Any]
    ) -> List[Any]:
        """ìŠ¤ë ˆë“œ ê¸°ë°˜ ë³‘ë ¬ map"""
        results = [None] * len(items)
        results_lock = Lock()
        
        def process_item(index: int, item: Any):
            result = func(item)
            with results_lock:
                results[index] = result
        
        threads = []
        for i, item in enumerate(items):
            t = threading.Thread(target=process_item, args=(i, item))
            t.start()
            threads.append(t)
            
            # ë™ì‹œ ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ
            if len(threads) >= self.max_workers:
                threads[0].join()
                threads.pop(0)
        
        # ë‚¨ì€ ìŠ¤ë ˆë“œ ëŒ€ê¸°
        for t in threads:
            t.join()
        
        return results
    
    def parallel_map_pool(
        self,
        func: Callable[[Any], Any],
        items: List[Any],
        chunksize: int = 1
    ) -> List[Any]:
        """ThreadPoolExecutor ê¸°ë°˜ ë³‘ë ¬ map"""
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            return list(executor.map(func, items, chunksize=chunksize))
    
    def producer_consumer_pattern(
        self,
        producer_func: Callable[[], Any],
        consumer_func: Callable[[Any], Any],
        num_consumers: int = 5,
        max_queue_size: int = 100
    ) -> List[Any]:
        """ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´"""
        work_queue = queue.Queue(maxsize=max_queue_size)
        results_queue = queue.Queue()
        stop_event = Event()
        
        def producer():
            """ìƒì‚°ì ìŠ¤ë ˆë“œ"""
            try:
                while not stop_event.is_set():
                    item = producer_func()
                    if item is None:
                        break
                    work_queue.put(item)
            finally:
                # ì¢…ë£Œ ì‹ í˜¸
                for _ in range(num_consumers):
                    work_queue.put(None)
        
        def consumer():
            """ì†Œë¹„ì ìŠ¤ë ˆë“œ"""
            while True:
                item = work_queue.get()
                if item is None:
                    break
                
                try:
                    result = consumer_func(item)
                    results_queue.put(result)
                except Exception as e:
                    results_queue.put({"error": str(e)})
                finally:
                    work_queue.task_done()
        
        # ìŠ¤ë ˆë“œ ì‹œì‘
        producer_thread = threading.Thread(target=producer)
        consumer_threads = [
            threading.Thread(target=consumer)
            for _ in range(num_consumers)
        ]
        
        producer_thread.start()
        for t in consumer_threads:
            t.start()
        
        # ì™„ë£Œ ëŒ€ê¸°
        producer_thread.join()
        for t in consumer_threads:
            t.join()
        
        # ê²°ê³¼ ìˆ˜ì§‘
        results = []
        while not results_queue.empty():
            results.append(results_queue.get())
        
        return results
    
    def get_statistics(self) -> dict:
        """ì²˜ë¦¬ í†µê³„"""
        if not self.results:
            return {"message": "No results available"}
        
        success_count = sum(1 for r in self.results if r.success)
        failed_count = len(self.results) - success_count
        total_duration = sum(r.duration for r in self.results)
        
        # ìŠ¤ë ˆë“œë³„ í†µê³„
        thread_stats = {}
        for result in self.results:
            tid = result.thread_id
            if tid not in thread_stats:
                thread_stats[tid] = {"count": 0, "duration": 0}
            thread_stats[tid]["count"] += 1
            thread_stats[tid]["duration"] += result.duration
        
        return {
            "total_files": len(self.results),
            "successful": success_count,
            "failed": failed_count,
            "total_duration": f"{total_duration:.2f}s",
            "average_duration": f"{total_duration / len(self.results):.2f}s",
            "throughput": f"{len(self.results) / total_duration:.2f} files/s",
            "threads_used": len(thread_stats),
            "thread_statistics": thread_stats
        }
    
    def save_results(self, output_file: str = "thread_results.json"):
        """ê²°ê³¼ ì €ì¥"""
        data = {
            "statistics": self.get_statistics(),
            "results": [
                {
                    "thread_id": r.thread_id,
                    "file_path": r.file_path,
                    "success": r.success,
                    "result": str(r.result) if r.result else None,
                    "error": r.error,
                    "duration": r.duration
                }
                for r in self.results
            ]
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def example_usage():
    """ì‚¬ìš© ì˜ˆì œ"""
    print("ğŸ§µ ìŠ¤ë ˆë“œ ê¸°ë°˜ íŒŒì¼ ì²˜ë¦¬ê¸° ì˜ˆì œ")
    print("=" * 60)
    
    # ë‹¨ì–´ ìˆ˜ ê³„ì‚° í•¨ìˆ˜
    def count_words(content: str) -> dict:
        words = content.split()
        return {
            "word_count": len(words),
            "unique_words": len(set(words)),
            "avg_word_length": sum(len(w) for w in words) / len(words) if words else 0
        }
    
    processor = ThreadProcessor(max_workers=5)
    
    # 1. ìŠ¤ë ˆë“œ í’€ ë°©ì‹
    print("\n1. ThreadPoolExecutor ë°©ì‹:")
    results = processor.process_directory_pool(
        directory=".",
        pattern="*.py",
        processor=count_words,
        recursive=False
    )
    
    # 2. í†µê³„ ì¶œë ¥
    print("\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
    stats = processor.get_statistics()
    for key, value in stats.items():
        if key != "thread_statistics":
            print(f"  {key}: {value}")
    
    # 3. ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´ ì˜ˆì œ
    print("\n2. ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´:")
    
    counter = [0]
    def producer():
        if counter[0] < 10:
            counter[0] += 1
            return f"Item {counter[0]}"
        return None
    
    def consumer(item):
        time.sleep(0.1)  # ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        return f"Processed: {item}"
    
    results = processor.producer_consumer_pattern(
        producer_func=producer,
        consumer_func=consumer,
        num_consumers=3
    )
    
    print(f"ì²˜ë¦¬ëœ ì•„ì´í…œ: {len(results)}ê°œ")


if __name__ == "__main__":
    example_usage()