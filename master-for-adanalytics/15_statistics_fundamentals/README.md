# 15. Statistics Fundamentals - í†µê³„í•™ ê¸°ì´ˆ

## ğŸ“š ê³¼ì • ì†Œê°œ
ê´‘ê³  ì„±ê³¼ ë¶„ì„ê³¼ ì‹¤í—˜ ì„¤ê³„ì— í•„ìš”í•œ í•µì‹¬ í†µê³„í•™ ê°œë…ì„ ë§ˆìŠ¤í„°í•©ë‹ˆë‹¤. A/B í…ŒìŠ¤íŠ¸, ì‹ ë¢°êµ¬ê°„, ê°€ì„¤ê²€ì •, ë² ì´ì§€ì•ˆ í†µê³„ë¥¼ ê´‘ê³  ë„ë©”ì¸ì— ì ìš©í•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- ê´‘ê³  ë°ì´í„° ê¸°ìˆ í†µê³„ ë¶„ì„
- A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„ ë° í•´ì„
- í†µê³„ì  ì¶”ë¡ ê³¼ ì˜ì‚¬ê²°ì •
- ë² ì´ì§€ì•ˆ ê´‘ê³  ìµœì í™”

## ğŸ“– ì£¼ìš” ë‚´ìš©

### ê´‘ê³  ë°ì´í„° ê¸°ìˆ í†µê³„
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

class AdStatisticsAnalyzer:
    """ê´‘ê³  í†µê³„ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.confidence_level = 0.95
        
    def descriptive_analysis(self, data: pd.DataFrame, metric: str) -> Dict:
        """ê¸°ìˆ í†µê³„ ë¶„ì„"""
        series = data[metric].dropna()
        
        # ê¸°ë³¸ í†µê³„ëŸ‰
        basic_stats = {
            'count': len(series),
            'mean': series.mean(),
            'median': series.median(),
            'mode': series.mode().iloc[0] if not series.mode().empty else None,
            'std': series.std(),
            'variance': series.var(),
            'min': series.min(),
            'max': series.max(),
            'range': series.max() - series.min()
        }
        
        # ë¶„ìœ„ìˆ˜
        quantiles = {
            'q25': series.quantile(0.25),
            'q50': series.quantile(0.50),  # median
            'q75': series.quantile(0.75),
            'iqr': series.quantile(0.75) - series.quantile(0.25)
        }
        
        # ë¶„í¬ íŠ¹ì„±
        distribution_stats = {
            'skewness': stats.skew(series),
            'kurtosis': stats.kurtosis(series),
            'cv': series.std() / series.mean() if series.mean() != 0 else np.inf
        }
        
        # ì´ìƒì¹˜ íƒì§€
        q1, q3 = quantiles['q25'], quantiles['q75']
        iqr = quantiles['iqr']
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        outliers = series[(series < lower_bound) | (series > upper_bound)]
        
        outlier_info = {
            'outlier_count': len(outliers),
            'outlier_percentage': len(outliers) / len(series) * 100,
            'outlier_values': outliers.tolist()[:10]  # ìƒìœ„ 10ê°œë§Œ
        }
        
        return {
            'basic_stats': basic_stats,
            'quantiles': quantiles,
            'distribution': distribution_stats,
            'outliers': outlier_info,
            'normality_test': self._test_normality(series)
        }
    
    def _test_normality(self, series: pd.Series) -> Dict:
        """ì •ê·œì„± ê²€ì •"""
        # Shapiro-Wilk test (n < 5000)
        if len(series) < 5000:
            shapiro_stat, shapiro_p = stats.shapiro(series)
            shapiro_result = {
                'statistic': shapiro_stat,
                'p_value': shapiro_p,
                'is_normal': shapiro_p > 0.05
            }
        else:
            shapiro_result = {'message': 'Sample too large for Shapiro-Wilk test'}
        
        # Kolmogorov-Smirnov test
        ks_stat, ks_p = stats.kstest(series, 'norm', 
                                     args=(series.mean(), series.std()))
        ks_result = {
            'statistic': ks_stat,
            'p_value': ks_p,
            'is_normal': ks_p > 0.05
        }
        
        return {
            'shapiro_wilk': shapiro_result,
            'kolmogorov_smirnov': ks_result
        }
    
    def compare_campaigns(self, data: pd.DataFrame, 
                         campaign_col: str, metric_col: str) -> Dict:
        """ìº í˜ì¸ ê°„ ë¹„êµ ë¶„ì„"""
        campaigns = data[campaign_col].unique()
        comparison_results = {}
        
        # ê° ìº í˜ì¸ë³„ ê¸°ìˆ í†µê³„
        for campaign in campaigns:
            campaign_data = data[data[campaign_col] == campaign][metric_col]
            comparison_results[campaign] = self.descriptive_analysis(
                pd.DataFrame({metric_col: campaign_data}), metric_col
            )
        
        # ì „ì²´ ANOVA í…ŒìŠ¤íŠ¸
        campaign_groups = [data[data[campaign_col] == camp][metric_col].dropna() 
                          for camp in campaigns]
        
        if len(campaign_groups) > 2:
            f_stat, p_value = stats.f_oneway(*campaign_groups)
            anova_result = {
                'f_statistic': f_stat,
                'p_value': p_value,
                'significant_difference': p_value < 0.05
            }
        else:
            anova_result = {'message': 'ANOVA requires at least 3 groups'}
        
        return {
            'campaign_stats': comparison_results,
            'anova_test': anova_result,
            'recommendations': self._generate_campaign_recommendations(comparison_results)
        }
    
    def _generate_campaign_recommendations(self, campaign_stats: Dict) -> List[str]:
        """ìº í˜ì¸ ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ì„±ê³¼ê°€ ê°€ì¥ ì¢‹ì€ ìº í˜ì¸ ì°¾ê¸°
        best_campaign = max(campaign_stats.keys(), 
                           key=lambda x: campaign_stats[x]['basic_stats']['mean'])
        worst_campaign = min(campaign_stats.keys(), 
                            key=lambda x: campaign_stats[x]['basic_stats']['mean'])
        
        recommendations.append(f"'{best_campaign}' ìº í˜ì¸ì´ ê°€ì¥ ë†’ì€ í‰ê·  ì„±ê³¼ë¥¼ ë³´ì„")
        recommendations.append(f"'{worst_campaign}' ìº í˜ì¸ ìµœì í™” í•„ìš”")
        
        # ë³€ë™ì„± ë¶„ì„
        most_stable = min(campaign_stats.keys(), 
                         key=lambda x: campaign_stats[x]['distribution']['cv'])
        recommendations.append(f"'{most_stable}' ìº í˜ì¸ì´ ê°€ì¥ ì•ˆì •ì ì¸ ì„±ê³¼ë¥¼ ë³´ì„")
        
        return recommendations

class ABTestAnalyzer:
    """A/B í…ŒìŠ¤íŠ¸ ë¶„ì„ê¸°"""
    
    def __init__(self, alpha: float = 0.05):
        self.alpha = alpha
        self.confidence_level = 1 - alpha
        
    def design_ab_test(self, baseline_rate: float, 
                      min_detectable_effect: float,
                      power: float = 0.8) -> Dict:
        """A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„"""
        from statsmodels.stats.power import ttest_power
        from statsmodels.stats.proportion import proportion_effectsize
        
        # íš¨ê³¼ í¬ê¸° ê³„ì‚°
        control_rate = baseline_rate
        treatment_rate = baseline_rate * (1 + min_detectable_effect)
        
        effect_size = proportion_effectsize(treatment_rate, control_rate)
        
        # í‘œë³¸ í¬ê¸° ê³„ì‚°
        from statsmodels.stats.power import tt_solve_power
        
        sample_size = tt_solve_power(
            effect_size=effect_size,
            power=power,
            alpha=self.alpha,
            alternative='two-sided'
        )
        
        # ì‹¤í–‰ ê¸°ê°„ ì¶”ì • (ì¼ì¼ ë°©ë¬¸ì ê¸°ì¤€)
        def estimate_duration(daily_visitors: int) -> int:
            total_sample_needed = sample_size * 2  # ë‘ ê·¸ë£¹
            return int(np.ceil(total_sample_needed / daily_visitors))
        
        return {
            'sample_size_per_group': int(np.ceil(sample_size)),
            'total_sample_size': int(np.ceil(sample_size * 2)),
            'effect_size': effect_size,
            'baseline_rate': control_rate,
            'target_rate': treatment_rate,
            'min_detectable_effect': min_detectable_effect,
            'power': power,
            'alpha': self.alpha,
            'duration_estimator': estimate_duration
        }
    
    def analyze_ab_test(self, control_data: Dict, 
                       treatment_data: Dict) -> Dict:
        """A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
        # ë°ì´í„° ì¶”ì¶œ
        control_conversions = control_data['conversions']
        control_visitors = control_data['visitors']
        treatment_conversions = treatment_data['conversions']
        treatment_visitors = treatment_data['visitors']
        
        # ì „í™˜ìœ¨ ê³„ì‚°
        control_rate = control_conversions / control_visitors
        treatment_rate = treatment_conversions / treatment_visitors
        
        # í†µê³„ì  ê²€ì •
        test_result = self._proportion_test(
            control_conversions, control_visitors,
            treatment_conversions, treatment_visitors
        )
        
        # ì‹ ë¢°êµ¬ê°„
        control_ci = self._proportion_confidence_interval(control_conversions, control_visitors)
        treatment_ci = self._proportion_confidence_interval(treatment_conversions, treatment_visitors)
        
        # íš¨ê³¼ í¬ê¸° ë° ì‹¤ìš©ì  ìœ ì˜ì„±
        relative_lift = (treatment_rate - control_rate) / control_rate
        absolute_lift = treatment_rate - control_rate
        
        # ë² ì´ì§€ì•ˆ ë¶„ì„
        bayesian_result = self._bayesian_ab_analysis(
            control_conversions, control_visitors,
            treatment_conversions, treatment_visitors
        )
        
        return {
            'control': {
                'visitors': control_visitors,
                'conversions': control_conversions,
                'rate': control_rate,
                'confidence_interval': control_ci
            },
            'treatment': {
                'visitors': treatment_visitors,
                'conversions': treatment_conversions,
                'rate': treatment_rate,
                'confidence_interval': treatment_ci
            },
            'test_results': test_result,
            'effect_size': {
                'absolute_lift': absolute_lift,
                'relative_lift': relative_lift,
                'lift_confidence_interval': self._lift_confidence_interval(
                    control_conversions, control_visitors,
                    treatment_conversions, treatment_visitors
                )
            },
            'bayesian_analysis': bayesian_result,
            'recommendation': self._generate_ab_recommendation(test_result, relative_lift)
        }
    
    def _proportion_test(self, x1: int, n1: int, x2: int, n2: int) -> Dict:
        """ë¹„ìœ¨ ê²€ì •"""
        from statsmodels.stats.proportion import proportions_ztest
        
        counts = np.array([x1, x2])
        nobs = np.array([n1, n2])
        
        z_stat, p_value = proportions_ztest(counts, nobs)
        
        return {
            'z_statistic': z_stat,
            'p_value': p_value,
            'is_significant': p_value < self.alpha,
            'confidence_level': self.confidence_level
        }
    
    def _proportion_confidence_interval(self, x: int, n: int) -> Tuple[float, float]:
        """ë¹„ìœ¨ ì‹ ë¢°êµ¬ê°„"""
        from statsmodels.stats.proportion import proportion_confint
        
        ci_lower, ci_upper = proportion_confint(x, n, alpha=self.alpha)
        return (ci_lower, ci_upper)
    
    def _lift_confidence_interval(self, x1: int, n1: int, x2: int, n2: int) -> Tuple[float, float]:
        """ë¦¬í”„íŠ¸ ì‹ ë¢°êµ¬ê°„"""
        p1 = x1 / n1
        p2 = x2 / n2
        
        # ë¸íƒ€ ë°©ë²• ì‚¬ìš©
        se_p1 = np.sqrt(p1 * (1 - p1) / n1)
        se_p2 = np.sqrt(p2 * (1 - p2) / n2)
        se_diff = np.sqrt(se_p1**2 + se_p2**2)
        
        diff = p2 - p1
        relative_lift = diff / p1 if p1 > 0 else 0
        
        # ê·¼ì‚¬ ì‹ ë¢°êµ¬ê°„
        z_critical = stats.norm.ppf(1 - self.alpha/2)
        margin_error = z_critical * se_diff / p1 if p1 > 0 else 0
        
        return (relative_lift - margin_error, relative_lift + margin_error)
    
    def _bayesian_ab_analysis(self, x1: int, n1: int, x2: int, n2: int) -> Dict:
        """ë² ì´ì§€ì•ˆ A/B í…ŒìŠ¤íŠ¸ ë¶„ì„"""
        # ë² íƒ€ ë¶„í¬ ì‚¬ìš© (ë² íƒ€-ì´í•­ ì¼¤ë ˆ ì‚¬ì „ë¶„í¬)
        # ê· ë“± ì‚¬ì „ë¶„í¬: Beta(1, 1)
        
        # ì‚¬í›„ë¶„í¬: Beta(1 + x, 1 + n - x)
        control_posterior = stats.beta(1 + x1, 1 + n1 - x1)
        treatment_posterior = stats.beta(1 + x2, 1 + n2 - x2)
        
        # ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
        n_samples = 100000
        control_samples = control_posterior.rvs(n_samples)
        treatment_samples = treatment_posterior.rvs(n_samples)
        
        # Treatmentê°€ Controlë³´ë‹¤ ì¢‹ì„ í™•ë¥ 
        prob_treatment_better = np.mean(treatment_samples > control_samples)
        
        # ë¦¬í”„íŠ¸ ë¶„í¬
        lift_samples = (treatment_samples - control_samples) / control_samples
        lift_mean = np.mean(lift_samples)
        lift_credible_interval = np.percentile(lift_samples, [2.5, 97.5])
        
        return {
            'prob_treatment_better': prob_treatment_better,
            'prob_control_better': 1 - prob_treatment_better,
            'expected_lift': lift_mean,
            'lift_credible_interval': lift_credible_interval,
            'control_posterior_mean': control_posterior.mean(),
            'treatment_posterior_mean': treatment_posterior.mean()
        }
    
    def _generate_ab_recommendation(self, test_result: Dict, relative_lift: float) -> str:
        """A/B í…ŒìŠ¤íŠ¸ ì¶”ì²œì‚¬í•­"""
        if test_result['is_significant']:
            if relative_lift > 0:
                return f"Treatment ë²„ì „ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ê²Œ ë” ì¢‹ìŒ (p={test_result['p_value']:.4f}). ì ìš© ê¶Œì¥."
            else:
                return f"Control ë²„ì „ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ê²Œ ë” ì¢‹ìŒ (p={test_result['p_value']:.4f}). Treatment ì¤‘ë‹¨ ê¶Œì¥."
        else:
            return f"í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ (p={test_result['p_value']:.4f}). ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ ë˜ëŠ” í…ŒìŠ¤íŠ¸ ê°œì„  í•„ìš”."

class BayesianOptimization:
    """ë² ì´ì§€ì•ˆ ê´‘ê³  ìµœì í™”"""
    
    def __init__(self):
        self.prior_params = {'alpha': 1, 'beta': 1}  # ë² íƒ€ ë¶„í¬ ì‚¬ì „ë¶„í¬
        
    def multi_armed_bandit_analysis(self, arm_data: Dict[str, Dict]) -> Dict:
        """ë‹¤ì¤‘ ì„ íƒì§€ ë°´ë”§ ë¶„ì„"""
        results = {}
        
        for arm_name, data in arm_data.items():
            successes = data['conversions']
            trials = data['impressions']
            failures = trials - successes
            
            # ë² íƒ€ ë¶„í¬ ì‚¬í›„ë¶„í¬
            posterior_alpha = self.prior_params['alpha'] + successes
            posterior_beta = self.prior_params['beta'] + failures
            
            posterior = stats.beta(posterior_alpha, posterior_beta)
            
            results[arm_name] = {
                'posterior_mean': posterior.mean(),
                'posterior_std': posterior.std(),
                'credible_interval_95': posterior.interval(0.95),
                'probability_best': 0  # ë‚˜ì¤‘ì— ê³„ì‚°
            }
        
        # ê° armì´ ìµœê³ ì¼ í™•ë¥  ê³„ì‚°
        n_samples = 100000
        samples = {}
        for arm in arm_data.keys():
            alpha = self.prior_params['alpha'] + arm_data[arm]['conversions']
            beta = self.prior_params['beta'] + (arm_data[arm]['impressions'] - arm_data[arm]['conversions'])
            samples[arm] = stats.beta(alpha, beta).rvs(n_samples)
        
        sample_df = pd.DataFrame(samples)
        for arm in arm_data.keys():
            results[arm]['probability_best'] = np.mean(
                sample_df[arm] == sample_df.max(axis=1)
            )
        
        # ì¶”ì²œì‚¬í•­
        best_arm = max(results.keys(), key=lambda x: results[x]['probability_best'])
        
        return {
            'arm_analysis': results,
            'recommended_arm': best_arm,
            'recommendation_confidence': results[best_arm]['probability_best'],
            'expected_regret': self._calculate_expected_regret(results)
        }
    
    def _calculate_expected_regret(self, results: Dict) -> float:
        """ì˜ˆìƒ í›„íšŒ ê³„ì‚°"""
        best_mean = max(arm['posterior_mean'] for arm in results.values())
        current_strategy_mean = np.mean([arm['posterior_mean'] for arm in results.values()])
        return best_mean - current_strategy_mean

class CausalInference:
    """ì¸ê³¼ì¶”ë¡  ë¶„ì„"""
    
    def __init__(self):
        pass
    
    def difference_in_differences(self, data: pd.DataFrame,
                                time_col: str, treatment_col: str,
                                outcome_col: str, pre_period: str) -> Dict:
        """ì´ì¤‘ì°¨ë¶„ë²• ë¶„ì„"""
        # ì „í›„ ê¸°ê°„ êµ¬ë¶„
        data['post_treatment'] = (data[time_col] >= pre_period).astype(int)
        
        # íšŒê·€ë¶„ì„
        from sklearn.linear_model import LinearRegression
        
        X = data[[treatment_col, 'post_treatment']].copy()
        X['interaction'] = X[treatment_col] * X['post_treatment']
        
        model = LinearRegression()
        model.fit(X, data[outcome_col])
        
        # ê³„ìˆ˜ í•´ì„
        treatment_effect = model.coef_[2]  # ìƒí˜¸ì‘ìš© í•­
        
        return {
            'did_estimate': treatment_effect,
            'coefficients': {
                'treatment': model.coef_[0],
                'post_period': model.coef_[1],
                'did_effect': model.coef_[2]
            },
            'r_squared': model.score(X, data[outcome_col])
        }
    
    def instrumental_variables(self, data: pd.DataFrame,
                             treatment_col: str, instrument_col: str,
                             outcome_col: str, controls: List[str] = None) -> Dict:
        """ë„êµ¬ë³€ìˆ˜ ë¶„ì„"""
        from sklearn.linear_model import LinearRegression
        
        # 1ë‹¨ê³„: ë„êµ¬ë³€ìˆ˜ë¡œ ì²˜ì¹˜ë³€ìˆ˜ ì˜ˆì¸¡
        X_first = data[[instrument_col]]
        if controls:
            X_first = pd.concat([X_first, data[controls]], axis=1)
        
        first_stage = LinearRegression()
        first_stage.fit(X_first, data[treatment_col])
        treatment_hat = first_stage.predict(X_first)
        
        # 2ë‹¨ê³„: ì˜ˆì¸¡ëœ ì²˜ì¹˜ë³€ìˆ˜ë¡œ ê²°ê³¼ë³€ìˆ˜ ì˜ˆì¸¡
        X_second = pd.DataFrame({'treatment_hat': treatment_hat})
        if controls:
            X_second = pd.concat([X_second, data[controls]], axis=1)
        
        second_stage = LinearRegression()
        second_stage.fit(X_second, data[outcome_col])
        
        return {
            'iv_estimate': second_stage.coef_[0],
            'first_stage_r2': first_stage.score(X_first, data[treatment_col]),
            'second_stage_r2': second_stage.score(X_second, data[outcome_col])
        }
```

## ğŸš€ í”„ë¡œì íŠ¸
1. **A/B í…ŒìŠ¤íŠ¸ ìë™í™” í”Œë«í¼**
2. **ë² ì´ì§€ì•ˆ ê´‘ê³  ìµœì í™” ì‹œìŠ¤í…œ**
3. **í†µê³„ì  ê´‘ê³  ì„±ê³¼ ëŒ€ì‹œë³´ë“œ**
4. **ì¸ê³¼ì¶”ë¡  ê¸°ë°˜ ìº í˜ì¸ íš¨ê³¼ ë¶„ì„**