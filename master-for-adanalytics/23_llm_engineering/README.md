# 23. LLM Engineering - LLM ì—”ì§€ë‹ˆì–´ë§

## ğŸ“š ê³¼ì • ì†Œê°œ
ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ë§ˆì¼€íŒ… ìë™í™” ë° ê´‘ê³  ì¹´í”¼ ìƒì„± ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤. RAG, LangChain, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ ë§ˆìŠ¤í„°í•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- LLMì„ í™œìš©í•œ ê´‘ê³  ì¹´í”¼ ìë™ ìƒì„±
- RAG ê¸°ë°˜ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ ì‹œìŠ¤í…œ
- ê³ ê° ìƒë‹´ ìë™í™”
- ë¹„ìš© íš¨ìœ¨ì ì¸ LLM ìš´ì˜

## ğŸ“– ì£¼ìš” ë‚´ìš©

### ê´‘ê³  ì¹´í”¼ ìƒì„± ì‹œìŠ¤í…œ
```python
from langchain import LLMChain, PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Pinecone
from langchain.memory import ConversationSummaryMemory
import pinecone

class AdCopyGenerator:
    """LLM ê¸°ë°˜ ê´‘ê³  ì¹´í”¼ ìƒì„±ê¸°"""
    
    def __init__(self, api_key):
        self.llm = ChatOpenAI(
            model_name="gpt-4",
            temperature=0.7,
            api_key=api_key
        )
        self.embeddings = OpenAIEmbeddings()
        self._init_vector_store()
        
    def _init_vector_store(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” (ì„±ê³µ ì‚¬ë¡€ DB)"""
        pinecone.init(api_key="YOUR_PINECONE_KEY")
        
        # ê¸°ì¡´ ì„±ê³µ ê´‘ê³  ì¹´í”¼ ì„ë² ë”©
        self.vectorstore = Pinecone.from_existing_index(
            "successful-ad-copies",
            self.embeddings
        )
    
    def generate_ad_copy(self, product_info, target_audience, tone="professional"):
        """ê´‘ê³  ì¹´í”¼ ìƒì„±"""
        # ìœ ì‚¬í•œ ì„±ê³µ ì‚¬ë¡€ ê²€ìƒ‰
        similar_ads = self.vectorstore.similarity_search(
            f"{product_info} {target_audience}",
            k=3
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        prompt = PromptTemplate(
            input_variables=["product", "audience", "tone", "examples"],
            template="""
            ë‹¹ì‹ ì€ ì „ë¬¸ ê´‘ê³  ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
            
            ì œí’ˆ ì •ë³´: {product}
            íƒ€ê²Ÿ ê³ ê°: {audience}
            í†¤ì•¤ë§¤ë„ˆ: {tone}
            
            ì„±ê³µ ì‚¬ë¡€:
            {examples}
            
            ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ë ¥ì ì¸ ê´‘ê³  ì¹´í”¼ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
            1. í—¤ë“œë¼ì¸ (15ì ì´ë‚´)
            2. ë³¸ë¬¸ (50ì ì´ë‚´)
            3. CTA (í–‰ë™ ìœ ë„ ë¬¸êµ¬)
            
            ì¶”ê°€ë¡œ A/B í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ë³€í˜• 2ê°œë„ ì œì•ˆí•´ì£¼ì„¸ìš”.
            """
        )
        
        # ì²´ì¸ ì‹¤í–‰
        chain = LLMChain(llm=self.llm, prompt=prompt)
        
        result = chain.run(
            product=product_info,
            audience=target_audience,
            tone=tone,
            examples="\n".join([ad.page_content for ad in similar_ads])
        )
        
        return self._parse_ad_copy(result)
    
    def optimize_existing_copy(self, current_copy, performance_data):
        """ê¸°ì¡´ ì¹´í”¼ ìµœì í™”"""
        optimization_prompt = f"""
        í˜„ì¬ ê´‘ê³  ì¹´í”¼:
        {current_copy}
        
        ì„±ê³¼ ë°ì´í„°:
        - CTR: {performance_data['ctr']}%
        - ì „í™˜ìœ¨: {performance_data['cvr']}%
        - ì£¼ìš” ì´íƒˆ ì§€ì : {performance_data['drop_off_point']}
        
        ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê´‘ê³  ì¹´í”¼ë¥¼ ê°œì„ í•´ì£¼ì„¸ìš”.
        ê°œì„  ì´ìœ ë„ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        """
        
        response = self.llm.predict(optimization_prompt)
        return response
```

### RAG ê¸°ë°˜ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸
```python
from langchain.chains import RetrievalQA
from langchain.document_loaders import S3DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

class MarketingInsightRAG:
    """RAG ê¸°ë°˜ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.llm = ChatOpenAI(model_name="gpt-3.5-turbo-16k")
        self._setup_knowledge_base()
        
    def _setup_knowledge_base(self):
        """ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì¶•"""
        # ë§ˆì¼€íŒ… ë¬¸ì„œ ë¡œë“œ
        loader = S3DirectoryLoader(
            bucket="marketing-knowledge",
            prefix="documents/"
        )
        documents = loader.load()
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        texts = text_splitter.split_documents(documents)
        
        # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        self.vectorstore = Pinecone.from_documents(
            texts,
            OpenAIEmbeddings(),
            index_name="marketing-knowledge"
        )
        
        # QA ì²´ì¸ ì„¤ì •
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(
                search_kwargs={"k": 5}
            )
        )
    
    def get_campaign_insights(self, campaign_data):
        """ìº í˜ì¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        query = f"""
        ë‹¤ìŒ ìº í˜ì¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
        
        ìº í˜ì¸: {campaign_data['name']}
        ê¸°ê°„: {campaign_data['period']}
        ì„±ê³¼:
        - ë…¸ì¶œ: {campaign_data['impressions']}
        - CTR: {campaign_data['ctr']}%
        - CPA: {campaign_data['cpa']}ì›
        - ROAS: {campaign_data['roas']}
        
        1. ì„±ê³¼ í‰ê°€
        2. ê°œì„  ë°©ì•ˆ
        3. ìœ ì‚¬ ì„±ê³µ ì‚¬ë¡€
        4. ë‹¤ìŒ ë‹¨ê³„ ì¶”ì²œ
        """
        
        response = self.qa_chain.run(query)
        return response
```

### LangChain ì›Œí¬í”Œë¡œìš°
```python
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.tools import DuckDuckGoSearchRun
from langchain.utilities import GoogleSerperAPIWrapper

class MarketingAutomationAgent:
    """ë§ˆì¼€íŒ… ìë™í™” ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.llm = ChatOpenAI(temperature=0)
        self.search = DuckDuckGoSearchRun()
        self.serper = GoogleSerperAPIWrapper()
        self._setup_tools()
        
    def _setup_tools(self):
        """ë„êµ¬ ì„¤ì •"""
        self.tools = [
            Tool(
                name="Search",
                func=self.search.run,
                description="ìµœì‹  ë§ˆì¼€íŒ… íŠ¸ë Œë“œ ê²€ìƒ‰"
            ),
            Tool(
                name="Competitor Analysis",
                func=self._analyze_competitor,
                description="ê²½ìŸì‚¬ ê´‘ê³  ë¶„ì„"
            ),
            Tool(
                name="Generate Copy",
                func=self._generate_copy,
                description="ê´‘ê³  ì¹´í”¼ ìƒì„±"
            ),
            Tool(
                name="Performance Prediction",
                func=self._predict_performance,
                description="ê´‘ê³  ì„±ê³¼ ì˜ˆì¸¡"
            )
        ]
        
        # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        self.agent = initialize_agent(
            self.tools,
            self.llm,
            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
            verbose=True
        )
    
    def create_campaign(self, brief):
        """ìº í˜ì¸ ìë™ ìƒì„±"""
        task = f"""
        ë‹¤ìŒ ë¸Œë¦¬í”„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™„ì „í•œ ê´‘ê³  ìº í˜ì¸ì„ ìƒì„±í•˜ì„¸ìš”:
        {brief}
        
        ìˆ˜í–‰í•  ì‘ì—…:
        1. ì‹œì¥ ë° ê²½ìŸì‚¬ ì¡°ì‚¬
        2. íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ ì •ì˜
        3. ê´‘ê³  ì¹´í”¼ 3ì¢… ìƒì„±
        4. ì˜ˆìƒ ì„±ê³¼ ë¶„ì„
        5. ì˜ˆì‚° ë°°ë¶„ ì œì•ˆ
        """
        
        result = self.agent.run(task)
        return result
```

### ë¹„ìš© ìµœì í™” ì „ëµ
```python
class LLMCostOptimizer:
    """LLM ë¹„ìš© ìµœì í™”"""
    
    def __init__(self):
        self.models = {
            'gpt-4': {'cost_per_1k': 0.03, 'quality': 0.95},
            'gpt-3.5-turbo': {'cost_per_1k': 0.002, 'quality': 0.85},
            'claude-2': {'cost_per_1k': 0.008, 'quality': 0.90}
        }
        
    def select_optimal_model(self, task_type, budget_constraint):
        """ì‘ì—…ë³„ ìµœì  ëª¨ë¸ ì„ íƒ"""
        if task_type == "creative_generation":
            # ì°½ì˜ì  ì‘ì—…ì€ ê³ í’ˆì§ˆ ëª¨ë¸
            return 'gpt-4'
        elif task_type == "data_extraction":
            # ë‹¨ìˆœ ì¶”ì¶œì€ ì €ë¹„ìš© ëª¨ë¸
            return 'gpt-3.5-turbo'
        else:
            # ë¹„ìš©/í’ˆì§ˆ ê· í˜•
            return 'claude-2'
    
    def implement_caching(self):
        """ì‘ë‹µ ìºì‹±ìœ¼ë¡œ ë¹„ìš© ì ˆê°"""
        from functools import lru_cache
        
        @lru_cache(maxsize=1000)
        def cached_llm_call(prompt_hash):
            # ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ëŠ” ìºì‹œì—ì„œ ë°˜í™˜
            pass
```

### í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
```python
class PromptOptimizer:
    """í”„ë¡¬í”„íŠ¸ ìµœì í™”"""
    
    def __init__(self):
        self.best_practices = {
            'clarity': 'ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ì§€ì‹œ',
            'examples': 'Few-shot ì˜ˆì‹œ ì œê³µ',
            'format': 'ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹ ëª…ì‹œ',
            'constraints': 'ì œì•½ ì¡°ê±´ ëª…í™•íˆ'
        }
    
    def optimize_prompt(self, base_prompt):
        """í”„ë¡¬í”„íŠ¸ ìµœì í™”"""
        optimized = f"""
        [ì‘ì—… ì»¨í…ìŠ¤íŠ¸]
        ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ë””ì§€í„¸ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        
        [ì‘ì—… ì§€ì‹œ]
        {base_prompt}
        
        [ì¶œë ¥ í˜•ì‹]
        - JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
        - ê° í•­ëª©ì— ëŒ€í•œ ê·¼ê±° í¬í•¨
        - ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì œì•ˆ
        
        [ì œì•½ ì¡°ê±´]
        - í•œêµ­ ì‹œì¥ íŠ¹ì„± ê³ ë ¤
        - ëª¨ë°”ì¼ ìš°ì„  ì ‘ê·¼
        - ê°œì¸ì •ë³´ ë³´í˜¸ ê·œì • ì¤€ìˆ˜
        """
        
        return optimized
```

## ğŸš€ í”„ë¡œì íŠ¸
1. **AI ê´‘ê³  ì¹´í”¼ë¼ì´í„°**
2. **ë§ˆì¼€íŒ… ì±—ë´‡ ì‹œìŠ¤í…œ**
3. **ìë™í™”ëœ A/B í…ŒìŠ¤íŠ¸ í”Œë«í¼**
4. **RAG ê¸°ë°˜ ë§ˆì¼€íŒ… ì§€ì‹ ê´€ë¦¬ ì‹œìŠ¤í…œ**