# 10. Pandas & Polars - íŒë‹¤ìŠ¤ì™€ í´ë¼ìŠ¤

## ğŸ“š ê³¼ì • ì†Œê°œ
ëŒ€ê·œëª¨ ê´‘ê³  ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ Pandasì™€ ê³ ì„±ëŠ¥ Polars ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë§ˆìŠ¤í„°í•©ë‹ˆë‹¤. ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° ë¶„ì„ë¶€í„° ë³‘ë ¬ ì²˜ë¦¬ê¹Œì§€ ì‹¤ë¬´ ê¸°ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- ëŒ€ìš©ëŸ‰ ê´‘ê³  ë°ì´í„° ì²˜ë¦¬ ìµœì í™”
- Pandas vs Polars ì„±ëŠ¥ ë¹„êµ
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°ì´í„° ë¶„ì„
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬

## ğŸ“– ì£¼ìš” ë‚´ìš©

### Pandas ê³ ê¸‰ í™œìš©
```python
import pandas as pd
import numpy as np
import polars as pl
import time
from typing import Dict, List
import warnings
warnings.filterwarnings('ignore')

class AdDataProcessor:
    """ê´‘ê³  ë°ì´í„° ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.campaign_data = None
        self.performance_data = None
        
    def load_large_dataset(self, file_path: str, chunk_size: int = 10000) -> pd.DataFrame:
        """ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²­í¬ ë‹¨ìœ„ ë¡œë”©"""
        chunks = []
        
        for chunk in pd.read_csv(file_path, chunksize=chunk_size):
            # ì²­í¬ë³„ ì „ì²˜ë¦¬
            processed_chunk = self.preprocess_chunk(chunk)
            chunks.append(processed_chunk)
            
        return pd.concat(chunks, ignore_index=True)
    
    def preprocess_chunk(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„° ì²­í¬ ì „ì²˜ë¦¬"""
        # ë°ì´í„° íƒ€ì… ìµœì í™”
        df = self.optimize_dtypes(df)
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        df = self.handle_missing_values(df)
        
        # íŒŒìƒ ë³€ìˆ˜ ìƒì„±
        df = self.create_derived_features(df)
        
        return df
    
    def optimize_dtypes(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„° íƒ€ì… ìµœì í™”ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ"""
        # ì •ìˆ˜í˜• ìµœì í™”
        for col in df.select_dtypes(include=['int64']).columns:
            df[col] = pd.to_numeric(df[col], downcast='integer')
        
        # ì‹¤ìˆ˜í˜• ìµœì í™”  
        for col in df.select_dtypes(include=['float64']).columns:
            df[col] = pd.to_numeric(df[col], downcast='float')
        
        # ì¹´í…Œê³ ë¦¬í˜• ë³€í™˜
        categorical_cols = ['campaign_type', 'device_type', 'platform', 'country']
        for col in categorical_cols:
            if col in df.columns:
                df[col] = df[col].astype('category')
        
        return df
    
    def handle_missing_values(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê²°ì¸¡ê°’ ì²˜ë¦¬"""
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜: 0ìœ¼ë¡œ ì±„ìš°ê¸°
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        df[numeric_cols] = df[numeric_cols].fillna(0)
        
        # ë²”ì£¼í˜• ë³€ìˆ˜: 'unknown'ìœ¼ë¡œ ì±„ìš°ê¸°
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns
        df[categorical_cols] = df[categorical_cols].fillna('unknown')
        
        return df
    
    def create_derived_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """íŒŒìƒ ë³€ìˆ˜ ìƒì„±"""
        if all(col in df.columns for col in ['clicks', 'impressions', 'cost', 'conversions']):
            # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
            df['ctr'] = df['clicks'] / df['impressions'].replace(0, np.nan)
            df['cpc'] = df['cost'] / df['clicks'].replace(0, np.nan)
            df['cvr'] = df['conversions'] / df['clicks'].replace(0, np.nan)
            df['cpa'] = df['cost'] / df['conversions'].replace(0, np.nan)
            
            # íš¨ìœ¨ì„± ì ìˆ˜
            df['efficiency_score'] = (df['conversions'] / (df['cost'] + 1)) * 100
        
        return df
    
    def advanced_groupby_operations(self, df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
        """ê³ ê¸‰ ê·¸ë£¹ë³„ ì—°ì‚°"""
        results = {}
        
        # ìº í˜ì¸ë³„ ì¼ë³„ ì„±ê³¼ íŠ¸ë Œë“œ
        daily_performance = (df.groupby(['campaign_id', 'date'])
                           .agg({
                               'impressions': 'sum',
                               'clicks': 'sum', 
                               'cost': 'sum',
                               'conversions': 'sum'
                           })
                           .reset_index())
        
        # ë¡¤ë§ í‰ê·  ê³„ì‚°
        daily_performance['impressions_7d_avg'] = (daily_performance
                                                 .groupby('campaign_id')['impressions']
                                                 .rolling(window=7, min_periods=1)
                                                 .mean()
                                                 .reset_index(drop=True))
        
        results['daily_performance'] = daily_performance
        
        # ë””ë°”ì´ìŠ¤ë³„ ì„±ê³¼ ë¹„êµ
        device_performance = (df.groupby('device_type')
                            .agg({
                                'impressions': 'sum',
                                'clicks': 'sum',
                                'cost': 'sum',
                                'conversions': 'sum',
                                'ctr': 'mean',
                                'cvr': 'mean'
                            })
                            .round(4))
        
        results['device_performance'] = device_performance
        
        # ìƒìœ„ ì„±ê³¼ ìº í˜ì¸
        top_campaigns = (df.groupby('campaign_id')
                        .agg({
                            'cost': 'sum',
                            'conversions': 'sum',
                            'cpa': 'mean'
                        })
                        .assign(roas=lambda x: x['conversions'] * 100 / x['cost'])
                        .sort_values('roas', ascending=False)
                        .head(10))
        
        results['top_campaigns'] = top_campaigns
        
        return results
    
    def cohort_analysis(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì½”í˜¸íŠ¸ ë¶„ì„"""
        # ì²« êµ¬ë§¤ ì›”ì„ ê¸°ì¤€ìœ¼ë¡œ ì½”í˜¸íŠ¸ ìƒì„±
        df['order_period'] = pd.to_datetime(df['date']).dt.to_period('M')
        df['cohort_group'] = df.groupby('customer_id')['order_period'].transform('min')
        
        # ê¸°ê°„ ë²ˆí˜¸ ê³„ì‚°
        def get_period_number(df):
            return (df['order_period'] - df['cohort_group']).apply(attrgetter('n'))
        
        df['period_number'] = get_period_number(df)
        
        # ì½”í˜¸íŠ¸ í…Œì´ë¸” ìƒì„±
        cohort_data = df.groupby(['cohort_group', 'period_number'])['customer_id'].nunique().reset_index()
        cohort_counts = cohort_data.pivot(index='cohort_group', 
                                         columns='period_number', 
                                         values='customer_id')
        
        # ì½”í˜¸íŠ¸ í¬ê¸°
        cohort_sizes = df.groupby('cohort_group')['customer_id'].nunique()
        
        # ìœ ì§€ìœ¨ ê³„ì‚°
        cohort_table = cohort_counts.divide(cohort_sizes, axis=0)
        
        return cohort_table

class PolarsProcessor:
    """Polarsë¥¼ í™œìš©í•œ ê³ ì„±ëŠ¥ ë°ì´í„° ì²˜ë¦¬"""
    
    def __init__(self):
        self.df = None
        
    def load_and_process(self, file_path: str) -> pl.DataFrame:
        """Polarsë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¡œë”© ë° ì²˜ë¦¬"""
        # LazyFrameìœ¼ë¡œ ë¡œë”© (ì§€ì—° í‰ê°€)
        lazy_df = (pl.scan_csv(file_path)
                  .with_columns([
                      # ë°ì´í„° íƒ€ì… ë³€í™˜
                      pl.col("date").str.strptime(pl.Date, format="%Y-%m-%d"),
                      pl.col("impressions").cast(pl.Int32),
                      pl.col("clicks").cast(pl.Int32),
                      pl.col("cost").cast(pl.Float32),
                      pl.col("conversions").cast(pl.Int16)
                  ])
                  .with_columns([
                      # íŒŒìƒ ë³€ìˆ˜ ìƒì„±
                      (pl.col("clicks") / pl.col("impressions")).alias("ctr"),
                      (pl.col("cost") / pl.col("clicks")).alias("cpc"),
                      (pl.col("conversions") / pl.col("clicks")).alias("cvr"),
                      (pl.col("cost") / pl.col("conversions")).alias("cpa")
                  ])
                  .filter(
                      # í•„í„°ë§
                      (pl.col("impressions") > 0) &
                      (pl.col("cost") > 0)
                  ))
        
        # ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜
        self.df = lazy_df.collect()
        return self.df
    
    def advanced_aggregations(self) -> Dict[str, pl.DataFrame]:
        """ê³ ê¸‰ ì§‘ê³„ ì—°ì‚°"""
        results = {}
        
        # ìº í˜ì¸ë³„ ì„±ê³¼ ìš”ì•½
        campaign_summary = (self.df
                           .group_by("campaign_id")
                           .agg([
                               pl.col("impressions").sum().alias("total_impressions"),
                               pl.col("clicks").sum().alias("total_clicks"),
                               pl.col("cost").sum().alias("total_cost"),
                               pl.col("conversions").sum().alias("total_conversions"),
                               pl.col("ctr").mean().alias("avg_ctr"),
                               pl.col("cpa").mean().alias("avg_cpa")
                           ])
                           .with_columns([
                               (pl.col("total_conversions") * 100 / pl.col("total_cost")).alias("roas")
                           ])
                           .sort("roas", descending=True))
        
        results['campaign_summary'] = campaign_summary
        
        # ì‹œê°„ë³„ íŠ¸ë Œë“œ ë¶„ì„
        time_trends = (self.df
                      .with_columns([
                          pl.col("date").dt.year().alias("year"),
                          pl.col("date").dt.month().alias("month"),
                          pl.col("date").dt.weekday().alias("weekday")
                      ])
                      .group_by(["year", "month", "weekday"])
                      .agg([
                          pl.col("impressions").sum(),
                          pl.col("clicks").sum(),
                          pl.col("cost").sum(),
                          pl.col("ctr").mean()
                      ]))
        
        results['time_trends'] = time_trends
        
        # ë””ë°”ì´ìŠ¤ë³„ ì„±ê³¼ ë¶„ì„
        device_analysis = (self.df
                          .group_by("device_type")
                          .agg([
                              pl.col("impressions").sum(),
                              pl.col("clicks").sum(),
                              pl.col("cost").sum(),
                              pl.col("conversions").sum(),
                              pl.col("ctr").mean(),
                              pl.col("cvr").mean()
                          ])
                          .with_columns([
                              (pl.col("clicks") / pl.col("impressions")).alias("overall_ctr"),
                              (pl.col("conversions") / pl.col("clicks")).alias("overall_cvr")
                          ]))
        
        results['device_analysis'] = device_analysis
        
        return results
    
    def window_functions(self) -> pl.DataFrame:
        """ìœˆë„ìš° í•¨ìˆ˜ í™œìš©"""
        result = (self.df
                 .sort(["campaign_id", "date"])
                 .with_columns([
                     # ìº í˜ì¸ë³„ ëˆ„ì  ë¹„ìš©
                     pl.col("cost").cumsum().over("campaign_id").alias("cumulative_cost"),
                     
                     # 7ì¼ ì´ë™ í‰ê· 
                     pl.col("impressions").rolling_mean(window_size=7).over("campaign_id").alias("impressions_7d_avg"),
                     
                     # ì „ì¼ ëŒ€ë¹„ ë³€í™”ìœ¨
                     (pl.col("clicks") / pl.col("clicks").shift(1).over("campaign_id") - 1).alias("clicks_change_rate"),
                     
                     # ìº í˜ì¸ë³„ ìˆœìœ„
                     pl.col("conversions").rank(method="dense", descending=True).over("campaign_id").alias("conversion_rank")
                 ]))
        
        return result
    
    def performance_benchmark(self, pandas_df: pd.DataFrame) -> Dict[str, float]:
        """Pandas vs Polars ì„±ëŠ¥ ë¹„êµ"""
        results = {}
        
        # Pandas ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        pandas_result = (pandas_df.groupby('campaign_id')
                        .agg({
                            'impressions': 'sum',
                            'clicks': 'sum',
                            'cost': 'sum'
                        }))
        pandas_time = time.time() - start_time
        results['pandas_time'] = pandas_time
        
        # Polars ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        polars_result = (self.df
                        .group_by("campaign_id")
                        .agg([
                            pl.col("impressions").sum(),
                            pl.col("clicks").sum(),
                            pl.col("cost").sum()
                        ]))
        polars_time = time.time() - start_time
        results['polars_time'] = polars_time
        
        results['speedup'] = pandas_time / polars_time
        
        return results

class StreamingDataProcessor:
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬"""
    
    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.buffer = []
        self.metrics = {
            'total_impressions': 0,
            'total_clicks': 0,
            'total_cost': 0.0,
            'running_ctr': 0.0
        }
    
    def process_stream_batch(self, batch_data: List[Dict]) -> Dict:
        """ìŠ¤íŠ¸ë¦¼ ë°°ì¹˜ ì²˜ë¦¬"""
        # ë°°ì¹˜ë¥¼ Polars DataFrameìœ¼ë¡œ ë³€í™˜
        batch_df = pl.DataFrame(batch_data)
        
        # ì‹¤ì‹œê°„ ì§€í‘œ ê³„ì‚°
        batch_metrics = (batch_df
                        .select([
                            pl.col("impressions").sum().alias("impressions"),
                            pl.col("clicks").sum().alias("clicks"), 
                            pl.col("cost").sum().alias("cost")
                        ])
                        .to_dicts()[0])
        
        # ëˆ„ì  ì§€í‘œ ì—…ë°ì´íŠ¸
        self.metrics['total_impressions'] += batch_metrics['impressions']
        self.metrics['total_clicks'] += batch_metrics['clicks']
        self.metrics['total_cost'] += batch_metrics['cost']
        
        # ì‹¤ì‹œê°„ CTR ê³„ì‚°
        if self.metrics['total_impressions'] > 0:
            self.metrics['running_ctr'] = self.metrics['total_clicks'] / self.metrics['total_impressions']
        
        # ì´ìƒ ê°ì§€
        anomalies = self.detect_anomalies(batch_df)
        
        return {
            'batch_size': len(batch_data),
            'batch_metrics': batch_metrics,
            'running_metrics': self.metrics.copy(),
            'anomalies': anomalies
        }
    
    def detect_anomalies(self, df: pl.DataFrame) -> List[Dict]:
        """ì´ìƒ ì§•í›„ ê°ì§€"""
        anomalies = []
        
        # CTR ì´ìƒ ê°ì§€
        avg_ctr = df.select(pl.col("clicks") / pl.col("impressions")).mean().item()
        if avg_ctr > 0.1:  # 10% ì´ìƒì˜ CTR
            anomalies.append({
                'type': 'high_ctr',
                'value': avg_ctr,
                'threshold': 0.1
            })
        
        # ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ì€ ë¹„ìš©
        high_cost_records = df.filter(pl.col("cost") > 10000).height
        if high_cost_records > 0:
            anomalies.append({
                'type': 'high_cost',
                'count': high_cost_records,
                'threshold': 10000
            })
        
        return anomalies
    
    def sliding_window_analysis(self, new_data: Dict) -> Dict:
        """ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë¶„ì„"""
        # ë²„í¼ì— ìƒˆ ë°ì´í„° ì¶”ê°€
        self.buffer.append(new_data)
        
        # ìœˆë„ìš° í¬ê¸° ìœ ì§€
        if len(self.buffer) > self.window_size:
            self.buffer.pop(0)
        
        # ìœˆë„ìš° ë°ì´í„° ë¶„ì„
        if len(self.buffer) >= 10:  # ìµœì†Œ 10ê°œ ë°ì´í„°
            window_df = pl.DataFrame(self.buffer)
            
            # íŠ¸ë Œë“œ ë¶„ì„
            trend_analysis = (window_df
                             .with_row_count("index")
                             .select([
                                 pl.corr("index", "impressions").alias("impression_trend"),
                                 pl.corr("index", "clicks").alias("click_trend"),
                                 pl.corr("index", "cost").alias("cost_trend")
                             ])
                             .to_dicts()[0])
            
            return {
                'window_size': len(self.buffer),
                'trends': trend_analysis,
                'latest_ctr': new_data.get('clicks', 0) / max(new_data.get('impressions', 1), 1)
            }
        
        return {'window_size': len(self.buffer), 'status': 'insufficient_data'}

# ì‚¬ìš© ì˜ˆì‹œ
def performance_comparison_demo():
    """ì„±ëŠ¥ ë¹„êµ ë°ëª¨"""
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    n_records = 100000
    
    data = {
        'campaign_id': np.random.choice(['camp_1', 'camp_2', 'camp_3'], n_records),
        'date': pd.date_range('2024-01-01', periods=n_records, freq='1min'),
        'impressions': np.random.randint(100, 1000, n_records),
        'clicks': np.random.randint(5, 100, n_records),
        'cost': np.random.uniform(10, 500, n_records),
        'conversions': np.random.randint(0, 10, n_records),
        'device_type': np.random.choice(['mobile', 'desktop', 'tablet'], n_records)
    }
    
    # Pandas DataFrame
    pandas_df = pd.DataFrame(data)
    
    # Polars ì²˜ë¦¬
    polars_processor = PolarsProcessor()
    
    # CSVë¡œ ì €ì¥ í›„ Polarsë¡œ ë¡œë”© (ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤)
    pandas_df.to_csv('sample_data.csv', index=False)
    polars_df = polars_processor.load_and_process('sample_data.csv')
    
    # ì„±ëŠ¥ ë¹„êµ
    benchmark_results = polars_processor.performance_benchmark(pandas_df)
    
    print(f"ì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
    print(f"Pandas ì²˜ë¦¬ ì‹œê°„: {benchmark_results['pandas_time']:.4f}ì´ˆ")
    print(f"Polars ì²˜ë¦¬ ì‹œê°„: {benchmark_results['polars_time']:.4f}ì´ˆ")
    print(f"Polars ì„±ëŠ¥ í–¥ìƒ: {benchmark_results['speedup']:.2f}ë°°")
    
    return benchmark_results

if __name__ == "__main__":
    results = performance_comparison_demo()
```

## ğŸš€ í”„ë¡œì íŠ¸
1. **ëŒ€ìš©ëŸ‰ ê´‘ê³  ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**
2. **ì‹¤ì‹œê°„ ì„±ê³¼ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ**
3. **ë©”ëª¨ë¦¬ ìµœì í™” ë¶„ì„ ë„êµ¬**
4. **ê³ ì„±ëŠ¥ ì½”í˜¸íŠ¸ ë¶„ì„ í”Œë«í¼**