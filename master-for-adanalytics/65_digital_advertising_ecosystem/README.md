# 65. Digital Advertising Ecosystem - ë””ì§€í„¸ ê´‘ê³  ìƒíƒœê³„

## ğŸ“š ê³¼ì • ì†Œê°œ
ë””ì§€í„¸ ê´‘ê³  ìƒíƒœê³„ì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ë§ˆìŠ¤í„°í•©ë‹ˆë‹¤. í”„ë¡œê·¸ë˜ë§¤í‹± ê±°ë˜ë¶€í„° ë¸Œëœë“œ ì„¸ì´í”„í‹°ê¹Œì§€ í˜„ëŒ€ ë””ì§€í„¸ ê´‘ê³ ì˜ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- í”„ë¡œê·¸ë˜ë§¤í‹± ê´‘ê³  ìƒíƒœê³„ì™€ RTB ë©”ì»¤ë‹ˆì¦˜ ì´í•´
- DSP/SSP/DMP/CDP í”Œë«í¼ ìš´ì˜ ì „ëµ
- ì¿ í‚¤ë¦¬ìŠ¤ í™˜ê²½ ëŒ€ì‘ê³¼ í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ ê´‘ê³ 
- ë¸Œëœë“œ ì„¸ì´í”„í‹°ì™€ ê´‘ê³  ì‚¬ê¸° íƒì§€ ì‹œìŠ¤í…œ

## ğŸ“– ì£¼ìš” ë‚´ìš©

### ë””ì§€í„¸ ê´‘ê³  ìƒíƒœê³„ ë¶„ì„ ì‹œìŠ¤í…œ
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import networkx as nx
import requests
import hashlib
import json
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

class DigitalAdvertisingEcosystem:
    """ë””ì§€í„¸ ê´‘ê³  ìƒíƒœê³„ ë¶„ì„ì„ ìœ„í•œ ì¢…í•© í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.rtb_simulator = RTBSimulator()
        self.fraud_detector = AdFraudDetector()
        self.brand_safety = BrandSafetyMonitor()
        self.privacy_manager = PrivacyComplianceManager()
        
    def programmatic_ecosystem_analysis(self, bid_data, inventory_data):
        """í”„ë¡œê·¸ë˜ë§¤í‹± ìƒíƒœê³„ ë¶„ì„"""
        
        # ê³µê¸‰ ê²½ë¡œ ìµœì í™” (Supply Path Optimization)
        def analyze_supply_path(bid_requests):
            """ê³µê¸‰ ê²½ë¡œ íš¨ìœ¨ì„± ë¶„ì„"""
            supply_chains = {}
            
            for _, bid in bid_requests.iterrows():
                # ê³µê¸‰ ì²´ì¸ ì¶”ì  (Publisher -> SSP -> Exchange -> DSP)
                chain_key = f"{bid['publisher_id']}->{bid['ssp_id']}->{bid['exchange_id']}"
                
                if chain_key not in supply_chains:
                    supply_chains[chain_key] = {
                        'bid_requests': 0,
                        'win_rate': 0,
                        'avg_cpm': 0,
                        'total_wins': 0,
                        'total_spend': 0
                    }
                
                supply_chains[chain_key]['bid_requests'] += 1
                if bid['won'] == 1:
                    supply_chains[chain_key]['total_wins'] += 1
                    supply_chains[chain_key]['total_spend'] += bid['winning_price']
            
            # íš¨ìœ¨ì„± ë©”íŠ¸ë¦­ ê³„ì‚°
            for chain in supply_chains.values():
                if chain['bid_requests'] > 0:
                    chain['win_rate'] = chain['total_wins'] / chain['bid_requests']
                if chain['total_wins'] > 0:
                    chain['avg_cpm'] = chain['total_spend'] / chain['total_wins']
            
            return supply_chains
        
        # ì¸ë²¤í† ë¦¬ í’ˆì§ˆ ë¶„ì„
        def analyze_inventory_quality(inventory):
            """ì¸ë²¤í† ë¦¬ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
            quality_scores = {}
            
            for _, inv in inventory.iterrows():
                domain_score = self._calculate_domain_authority(inv['domain'])
                viewability_score = inv['viewability_rate']
                brand_safety_score = inv['brand_safety_score']
                fraud_score = 1 - inv['fraud_probability']  # ì‚¬ê¸° í™•ë¥ ì´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
                
                # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                quality_score = (
                    domain_score * 0.3 +
                    viewability_score * 0.3 +
                    brand_safety_score * 0.2 +
                    fraud_score * 0.2
                )
                
                quality_scores[inv['inventory_id']] = {
                    'domain_authority': domain_score,
                    'viewability': viewability_score,
                    'brand_safety': brand_safety_score,
                    'fraud_risk': 1 - fraud_score,
                    'overall_quality': quality_score
                }
            
            return quality_scores
        
        # ê³µê¸‰ ì²´ì¸ ë¶„ì„
        supply_path_analysis = analyze_supply_path(bid_data)
        
        # ì¸ë²¤í† ë¦¬ í’ˆì§ˆ ë¶„ì„
        inventory_quality = analyze_inventory_quality(inventory_data)
        
        # ë¹„ë”© íš¨ìœ¨ì„± ë¶„ì„
        bidding_efficiency = self._analyze_bidding_efficiency(bid_data)
        
        # ìƒíƒœê³„ ë§µ ìƒì„±
        ecosystem_map = self._create_ecosystem_network(bid_data, inventory_data)
        
        return {
            'supply_path_analysis': supply_path_analysis,
            'inventory_quality': inventory_quality,
            'bidding_efficiency': bidding_efficiency,
            'ecosystem_network': ecosystem_map
        }
    
    def rtb_auction_simulation(self, bid_requests, advertiser_profiles):
        """RTB ê²½ë§¤ ì‹œë®¬ë ˆì´ì…˜"""
        
        auction_results = []
        
        for _, bid_request in bid_requests.iterrows():
            # ê° ê´‘ê³ ì£¼ì˜ ì…ì°° ê²°ì •
            bids = []
            
            for advertiser_id, profile in advertiser_profiles.items():
                # íƒ€ê²ŸíŒ… ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                targeting_score = self._calculate_targeting_match(
                    bid_request, profile['targeting_criteria']
                )
                
                if targeting_score > profile['min_targeting_threshold']:
                    # ì…ì°°ê°€ ê³„ì‚° (ê°€ì¹˜ ê¸°ë°˜)
                    base_bid = profile['base_cpm']
                    bid_modifier = targeting_score * profile['targeting_multiplier']
                    
                    # ì˜ˆì‚° ì œì•½ í™•ì¸
                    if profile['remaining_budget'] > base_bid * bid_modifier:
                        final_bid = base_bid * bid_modifier
                        
                        bids.append({
                            'advertiser_id': advertiser_id,
                            'bid_amount': final_bid,
                            'targeting_score': targeting_score,
                            'creative_id': profile['creative_id']
                        })
            
            # ê²½ë§¤ ì‹¤í–‰ (2ì°¨ ê°€ê²© ê²½ë§¤)
            if len(bids) > 0:
                # ì…ì°°ê°€ ìˆœìœ¼ë¡œ ì •ë ¬
                bids_sorted = sorted(bids, key=lambda x: x['bid_amount'], reverse=True)
                
                winner = bids_sorted[0]
                
                # 2ì°¨ ê°€ê²© (ë‘ ë²ˆì§¸ë¡œ ë†’ì€ ì…ì°°ê°€ + 0.01)
                if len(bids_sorted) > 1:
                    clearing_price = bids_sorted[1]['bid_amount'] + 0.01
                else:
                    clearing_price = winner['bid_amount']  # ë‹¨ì¼ ì…ì°°ì
                
                # ê´‘ê³ ì£¼ ì˜ˆì‚° ì°¨ê°
                advertiser_profiles[winner['advertiser_id']]['remaining_budget'] -= clearing_price
                
                auction_result = {
                    'bid_request_id': bid_request['bid_request_id'],
                    'winner_id': winner['advertiser_id'],
                    'winning_bid': winner['bid_amount'],
                    'clearing_price': clearing_price,
                    'targeting_score': winner['targeting_score'],
                    'total_bidders': len(bids),
                    'auction_time': bid_request['timestamp']
                }
            else:
                # ì…ì°°ì ì—†ìŒ
                auction_result = {
                    'bid_request_id': bid_request['bid_request_id'],
                    'winner_id': None,
                    'winning_bid': 0,
                    'clearing_price': 0,
                    'targeting_score': 0,
                    'total_bidders': 0,
                    'auction_time': bid_request['timestamp']
                }
            
            auction_results.append(auction_result)
        
        # ê²½ë§¤ ì„±ê³¼ ë¶„ì„
        auction_analytics = self._analyze_auction_performance(auction_results, advertiser_profiles)
        
        return {
            'auction_results': pd.DataFrame(auction_results),
            'final_advertiser_budgets': advertiser_profiles,
            'auction_analytics': auction_analytics
        }
    
    def cookieless_advertising_strategy(self, user_data, contextual_data, first_party_data):
        """ì¿ í‚¤ë¦¬ìŠ¤ ê´‘ê³  ì „ëµ"""
        
        # 1. ì»¨í…ìŠ¤ì¶”ì–¼ íƒ€ê²ŸíŒ…
        contextual_targeting = self._build_contextual_targeting_model(contextual_data)
        
        # 2. ì½”í˜¸íŠ¸ ê¸°ë°˜ íƒ€ê²ŸíŒ… (Topics API ì‹œë®¬ë ˆì´ì…˜)
        cohort_targeting = self._create_privacy_preserving_cohorts(user_data)
        
        # 3. í¼ìŠ¤íŠ¸íŒŒí‹° ë°ì´í„° í™œìš©
        first_party_insights = self._analyze_first_party_data(first_party_data)
        
        # 4. í™•ë¥ ì  ë§¤ì¹­ (probabilistic matching)
        identity_resolution = self._probabilistic_identity_matching(user_data, first_party_data)
        
        # 5. ì—°í•© í•™ìŠµ ì‹œë®¬ë ˆì´ì…˜
        federated_model = self._simulate_federated_learning(user_data)
        
        # ì„±ê³¼ ì˜ˆì¸¡ ëª¨ë¸
        cookieless_performance = self._predict_cookieless_performance(
            contextual_targeting, cohort_targeting, first_party_insights
        )
        
        return {
            'contextual_targeting': contextual_targeting,
            'cohort_targeting': cohort_targeting,
            'first_party_insights': first_party_insights,
            'identity_resolution': identity_resolution,
            'federated_learning': federated_model,
            'performance_prediction': cookieless_performance
        }
    
    def brand_safety_monitoring(self, content_data, ad_placements):
        """ë¸Œëœë“œ ì„¸ì´í”„í‹° ëª¨ë‹ˆí„°ë§"""
        
        # ì»¨í…ì¸  ì•ˆì „ì„± ë¶„ì„
        content_safety_scores = {}
        
        for _, content in content_data.iterrows():
            # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ„í—˜ë„ ë¶„ì„
            risk_keywords = self._detect_risk_keywords(content['content_text'])
            
            # ê°ì • ë¶„ì„
            sentiment_score = self._analyze_content_sentiment(content['content_text'])
            
            # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            content_category = self._classify_content_category(content['content_text'])
            
            # ì¢…í•© ì•ˆì „ì„± ì ìˆ˜
            safety_score = self._calculate_brand_safety_score(
                risk_keywords, sentiment_score, content_category
            )
            
            content_safety_scores[content['content_id']] = {
                'risk_keywords': risk_keywords,
                'sentiment_score': sentiment_score,
                'content_category': content_category,
                'safety_score': safety_score,
                'safe_for_advertising': safety_score > 0.7
            }
        
        # ê´‘ê³  ë°°ì¹˜ ìœ„í—˜ë„ ë¶„ì„
        placement_risks = self._analyze_placement_risks(ad_placements, content_safety_scores)
        
        # ë¸Œëœë“œë³„ ë§ì¶¤ ì•ˆì „ì„± ê¸°ì¤€
        brand_specific_safety = self._create_brand_safety_profiles(ad_placements)
        
        # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì•ŒëŸ¿
        safety_alerts = self._generate_safety_alerts(placement_risks, brand_specific_safety)
        
        return {
            'content_safety_scores': content_safety_scores,
            'placement_risks': placement_risks,
            'brand_safety_profiles': brand_specific_safety,
            'safety_alerts': safety_alerts,
            'safety_dashboard_data': self._prepare_safety_dashboard(content_safety_scores, placement_risks)
        }
    
    def ad_fraud_detection(self, traffic_data, click_data, conversion_data):
        """ê´‘ê³  ì‚¬ê¸° íƒì§€"""
        
        # ë‹¤ì–‘í•œ ì‚¬ê¸° íŒ¨í„´ íƒì§€
        fraud_indicators = {
            'click_fraud': self._detect_click_fraud(click_data),
            'impression_fraud': self._detect_impression_fraud(traffic_data),
            'conversion_fraud': self._detect_conversion_fraud(conversion_data),
            'bot_traffic': self._detect_bot_traffic(traffic_data),
            'domain_spoofing': self._detect_domain_spoofing(traffic_data)
        }
        
        # ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì´ìƒ íƒì§€
        ml_fraud_detection = self._ml_fraud_detection(traffic_data, click_data)
        
        # ì‚¬ê¸° ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°
        fraud_risk_scores = self._calculate_fraud_risk_scores(fraud_indicators, ml_fraud_detection)
        
        # ì‚¬ê¸° ë°©ì§€ ê¶Œê³ ì‚¬í•­
        fraud_prevention_recommendations = self._generate_fraud_prevention_recommendations(
            fraud_risk_scores, fraud_indicators
        )
        
        return {
            'fraud_indicators': fraud_indicators,
            'ml_detection_results': ml_fraud_detection,
            'fraud_risk_scores': fraud_risk_scores,
            'prevention_recommendations': fraud_prevention_recommendations,
            'fraud_monitoring_dashboard': self._create_fraud_dashboard(fraud_indicators, fraud_risk_scores)
        }
    
    def data_clean_room_simulation(self, advertiser_data, publisher_data, privacy_budget=1.0):
        """ë°ì´í„° í´ë¦°ë£¸ ì‹œë®¬ë ˆì´ì…˜"""
        
        # ì°¨ë“± í”„ë¼ì´ë²„ì‹œ ì ìš©
        def add_differential_privacy_noise(data, epsilon=1.0):
            """ì°¨ë“± í”„ë¼ì´ë²„ì‹œ ë…¸ì´ì¦ˆ ì¶”ê°€"""
            sensitivity = 1.0  # ë°ì´í„° ë¯¼ê°ë„
            noise_scale = sensitivity / epsilon
            
            noise = np.random.laplace(0, noise_scale, data.shape)
            return data + noise
        
        # ì•ˆì „í•œ ì§‘ê³„ ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        clean_room_queries = {
            'audience_overlap': self._calculate_safe_audience_overlap(
                advertiser_data, publisher_data, privacy_budget * 0.3
            ),
            'conversion_attribution': self._safe_attribution_analysis(
                advertiser_data, publisher_data, privacy_budget * 0.3
            ),
            'lookalike_modeling': self._privacy_preserving_lookalike(
                advertiser_data, publisher_data, privacy_budget * 0.4
            )
        }
        
        # í”„ë¼ì´ë²„ì‹œ ì˜ˆì‚° ì¶”ì 
        remaining_budget = privacy_budget - sum([0.3, 0.3, 0.4])
        
        # ì¿¼ë¦¬ ê²°ê³¼ ê²€ì¦
        query_validation = self._validate_clean_room_queries(clean_room_queries)
        
        return {
            'clean_room_queries': clean_room_queries,
            'remaining_privacy_budget': remaining_budget,
            'query_validation': query_validation,
            'privacy_audit_log': self._create_privacy_audit_log(clean_room_queries)
        }

class RTBSimulator:
    """RTB ì‹œë®¬ë ˆì´ì…˜ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.auction_history = []
    
    def simulate_bid_request(self, user_profile, inventory_info):
        """ì…ì°° ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜"""
        bid_request = {
            'id': self._generate_request_id(),
            'timestamp': datetime.now(),
            'user_profile': user_profile,
            'inventory': inventory_info,
            'floor_price': inventory_info.get('floor_price', 0.5),
            'auction_type': 2  # 2ì°¨ ê°€ê²© ê²½ë§¤
        }
        
        return bid_request
    
    def _generate_request_id(self):
        """ê³ ìœ  ìš”ì²­ ID ìƒì„±"""
        return hashlib.md5(str(datetime.now()).encode()).hexdigest()[:16]

class AdFraudDetector:
    """ê´‘ê³  ì‚¬ê¸° íƒì§€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.fraud_patterns = {
            'click_fraud_threshold': 0.1,  # 10% ì´ìƒ í´ë¦­ìœ¨ì€ ì˜ì‹¬
            'bot_traffic_indicators': ['unusual_user_agent', 'datacenter_ip', 'high_frequency_clicks'],
            'domain_spoofing_patterns': ['similar_domains', 'typosquatting']
        }
    
    def detect_anomalies(self, traffic_data):
        """ì´ìƒ íŒ¨í„´ íƒì§€"""
        anomalies = []
        
        # í´ë¦­ íŒ¨í„´ ë¶„ì„
        click_rates = traffic_data.groupby('source_id')['clicks'].sum() / traffic_data.groupby('source_id')['impressions'].sum()
        suspicious_sources = click_rates[click_rates > self.fraud_patterns['click_fraud_threshold']].index
        
        for source in suspicious_sources:
            anomalies.append({
                'type': 'suspicious_click_rate',
                'source_id': source,
                'click_rate': click_rates[source],
                'risk_level': 'high' if click_rates[source] > 0.2 else 'medium'
            })
        
        return anomalies

class BrandSafetyMonitor:
    """ë¸Œëœë“œ ì„¸ì´í”„í‹° ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.risk_categories = {
            'adult_content': ['adult', 'explicit', 'mature'],
            'violence': ['violence', 'weapon', 'crime'],
            'hate_speech': ['hate', 'discrimination', 'offensive'],
            'fake_news': ['misinformation', 'conspiracy', 'fake']
        }
    
    def assess_content_safety(self, content_text):
        """ì»¨í…ì¸  ì•ˆì „ì„± í‰ê°€"""
        risk_score = 0
        detected_risks = []
        
        content_lower = content_text.lower()
        
        for category, keywords in self.risk_categories.items():
            for keyword in keywords:
                if keyword in content_lower:
                    risk_score += 0.2
                    detected_risks.append(category)
        
        safety_score = max(0, 1 - risk_score)
        
        return {
            'safety_score': safety_score,
            'detected_risks': list(set(detected_risks)),
            'safe_for_advertising': safety_score > 0.7
        }

class PrivacyComplianceManager:
    """í”„ë¼ì´ë²„ì‹œ ì»´í”Œë¼ì´ì–¸ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.compliance_frameworks = ['GDPR', 'CCPA', 'COPPA']
        self.consent_requirements = {
            'GDPR': ['explicit_consent', 'data_minimization', 'right_to_deletion'],
            'CCPA': ['opt_out_rights', 'data_disclosure', 'non_discrimination'],
            'COPPA': ['parental_consent', 'limited_data_collection', 'safe_harbor']
        }
    
    def check_compliance(self, data_processing_activity):
        """ì»´í”Œë¼ì´ì–¸ìŠ¤ ì²´í¬"""
        compliance_status = {}
        
        for framework in self.compliance_frameworks:
            requirements = self.consent_requirements[framework]
            met_requirements = []
            
            for requirement in requirements:
                if self._check_requirement(data_processing_activity, requirement):
                    met_requirements.append(requirement)
            
            compliance_status[framework] = {
                'compliant': len(met_requirements) == len(requirements),
                'met_requirements': met_requirements,
                'missing_requirements': list(set(requirements) - set(met_requirements))
            }
        
        return compliance_status
    
    def _check_requirement(self, activity, requirement):
        """ê°œë³„ ìš”êµ¬ì‚¬í•­ ì²´í¬"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”
        return requirement in activity.get('compliance_measures', [])

# ë³´ì¡° ë©”ì„œë“œë“¤
def _calculate_domain_authority(domain):
    """ë„ë©”ì¸ ê¶Œìœ„ë„ ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)"""
    # ì‹¤ì œë¡œëŠ” ì™¸ë¶€ API ë˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
    domain_scores = {
        'google.com': 0.95,
        'facebook.com': 0.90,
        'nytimes.com': 0.85,
        'unknown.com': 0.3
    }
    return domain_scores.get(domain, np.random.uniform(0.2, 0.8))

def _analyze_bidding_efficiency(bid_data):
    """ë¹„ë”© íš¨ìœ¨ì„± ë¶„ì„"""
    efficiency_metrics = {
        'win_rate': (bid_data['won'] == 1).mean(),
        'avg_winning_price': bid_data[bid_data['won'] == 1]['winning_price'].mean(),
        'bid_to_win_ratio': bid_data['bid_amount'].mean() / bid_data[bid_data['won'] == 1]['winning_price'].mean(),
        'budget_utilization': bid_data[bid_data['won'] == 1]['winning_price'].sum() / bid_data['budget_allocated'].sum()
    }
    
    return efficiency_metrics

# ì‹¤ìŠµ ì˜ˆì œ: ì¢…í•© ë””ì§€í„¸ ê´‘ê³  ìƒíƒœê³„ ë¶„ì„
def comprehensive_digital_ecosystem_analysis():
    """ì¢…í•©ì ì¸ ë””ì§€í„¸ ê´‘ê³  ìƒíƒœê³„ ë¶„ì„"""
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    np.random.seed(42)
    
    # RTB ì…ì°° ë°ì´í„°
    bid_data = pd.DataFrame({
        'bid_request_id': [f'br_{i}' for i in range(10000)],
        'publisher_id': np.random.choice(['pub_1', 'pub_2', 'pub_3', 'pub_4'], 10000),
        'ssp_id': np.random.choice(['ssp_1', 'ssp_2', 'ssp_3'], 10000),
        'exchange_id': np.random.choice(['ex_1', 'ex_2'], 10000),
        'bid_amount': np.random.uniform(0.5, 10.0, 10000),
        'winning_price': np.random.uniform(0.1, 8.0, 10000),
        'won': np.random.choice([0, 1], 10000, p=[0.8, 0.2]),
        'budget_allocated': np.random.uniform(1000, 50000, 10000),
        'timestamp': pd.date_range('2024-01-01', periods=10000, freq='1min')
    })
    
    # ì¸ë²¤í† ë¦¬ ë°ì´í„°
    inventory_data = pd.DataFrame({
        'inventory_id': [f'inv_{i}' for i in range(1000)],
        'domain': np.random.choice(['google.com', 'facebook.com', 'nytimes.com', 'unknown.com'], 1000),
        'viewability_rate': np.random.uniform(0.3, 0.95, 1000),
        'brand_safety_score': np.random.uniform(0.5, 1.0, 1000),
        'fraud_probability': np.random.uniform(0.0, 0.3, 1000)
    })
    
    # íŠ¸ë˜í”½ ë°ì´í„° (ì‚¬ê¸° íƒì§€ìš©)
    traffic_data = pd.DataFrame({
        'source_id': [f'src_{i}' for i in range(500)],
        'impressions': np.random.poisson(1000, 500),
        'clicks': np.random.poisson(50, 500),
        'user_agent': np.random.choice(['normal', 'suspicious', 'bot'], 500, p=[0.8, 0.15, 0.05]),
        'ip_type': np.random.choice(['residential', 'datacenter', 'mobile'], 500, p=[0.7, 0.2, 0.1]),
        'click_pattern': np.random.choice(['normal', 'burst', 'regular'], 500, p=[0.7, 0.2, 0.1])
    })
    
    # ì»¨í…ì¸  ë°ì´í„° (ë¸Œëœë“œ ì„¸ì´í”„í‹°ìš©)
    content_samples = [
        "Breaking news about technology trends",
        "Sports match results and highlights", 
        "Cooking recipes and food reviews",
        "Adult content warning mature themes",
        "Violence in latest action movie",
        "Political debate and opinions"
    ]
    
    content_data = pd.DataFrame({
        'content_id': [f'content_{i}' for i in range(100)],
        'content_text': np.random.choice(content_samples, 100),
        'domain': np.random.choice(['news.com', 'sports.com', 'food.com', 'adult.com'], 100)
    })
    
    # ê´‘ê³  ë°°ì¹˜ ë°ì´í„°
    ad_placements = pd.DataFrame({
        'placement_id': [f'pl_{i}' for i in range(200)],
        'content_id': [f'content_{i}' for i in np.random.randint(0, 100, 200)],
        'brand_id': np.random.choice(['brand_A', 'brand_B', 'brand_C'], 200),
        'campaign_type': np.random.choice(['awareness', 'conversion', 'retargeting'], 200)
    })
    
    # ìƒíƒœê³„ ë¶„ì„ ë„êµ¬ ì´ˆê¸°í™”
    ecosystem = DigitalAdvertisingEcosystem()
    
    # 1. í”„ë¡œê·¸ë˜ë§¤í‹± ìƒíƒœê³„ ë¶„ì„
    programmatic_analysis = ecosystem.programmatic_ecosystem_analysis(bid_data, inventory_data)
    
    # 2. ë¸Œëœë“œ ì„¸ì´í”„í‹° ë¶„ì„
    brand_safety_results = ecosystem.brand_safety_monitoring(content_data, ad_placements)
    
    # 3. ê´‘ê³  ì‚¬ê¸° íƒì§€
    fraud_detection_results = ecosystem.ad_fraud_detection(traffic_data, traffic_data, traffic_data)
    
    # ê²°ê³¼ ì¶œë ¥
    print("=== ë””ì§€í„¸ ê´‘ê³  ìƒíƒœê³„ ë¶„ì„ ê²°ê³¼ ===")
    
    print("\ní”„ë¡œê·¸ë˜ë§¤í‹± ë¶„ì„:")
    print(f"- ê³µê¸‰ ì²´ì¸ ìˆ˜: {len(programmatic_analysis['supply_path_analysis'])}ê°œ")
    print(f"- í‰ê·  ì¸ë²¤í† ë¦¬ í’ˆì§ˆ: {np.mean([q['overall_quality'] for q in programmatic_analysis['inventory_quality'].values()]):.3f}")
    
    print("\në¸Œëœë“œ ì„¸ì´í”„í‹°:")
    safe_content = sum(1 for score in brand_safety_results['content_safety_scores'].values() if score['safe_for_advertising'])
    print(f"- ì•ˆì „í•œ ì»¨í…ì¸  ë¹„ìœ¨: {safe_content/len(brand_safety_results['content_safety_scores'])*100:.1f}%")
    print(f"- ì•ˆì „ì„± ì•ŒëŸ¿ ìˆ˜: {len(brand_safety_results['safety_alerts'])}ê°œ")
    
    print("\nì‚¬ê¸° íƒì§€:")
    high_risk_sources = sum(1 for score in fraud_detection_results['fraud_risk_scores'].values() if score > 0.7)
    print(f"- ê³ ìœ„í—˜ ì†ŒìŠ¤: {high_risk_sources}ê°œ")
    print(f"- íƒì§€ëœ ì‚¬ê¸° íŒ¨í„´: {len([p for patterns in fraud_detection_results['fraud_indicators'].values() for p in patterns])}ê°œ")
    
    # ì‹œê°í™”
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. ì…ì°° ì„±ê³¼ ë¶„í¬
    axes[0, 0].hist(bid_data[bid_data['won'] == 1]['winning_price'], bins=30, alpha=0.7, label='Winning Prices')
    axes[0, 0].hist(bid_data['bid_amount'], bins=30, alpha=0.5, label='Bid Amounts')
    axes[0, 0].set_xlabel('Price (CPM)')
    axes[0, 0].set_ylabel('Frequency')
    axes[0, 0].set_title('Bid vs Winning Price Distribution')
    axes[0, 0].legend()
    
    # 2. ì¸ë²¤í† ë¦¬ í’ˆì§ˆ ë¶„í¬
    quality_scores = [q['overall_quality'] for q in programmatic_analysis['inventory_quality'].values()]
    axes[0, 1].hist(quality_scores, bins=20, alpha=0.7, color='green')
    axes[0, 1].set_xlabel('Quality Score')
    axes[0, 1].set_ylabel('Frequency')
    axes[0, 1].set_title('Inventory Quality Distribution')
    
    # 3. ë¸Œëœë“œ ì„¸ì´í”„í‹° ì ìˆ˜
    safety_scores = [score['safety_score'] for score in brand_safety_results['content_safety_scores'].values()]
    axes[1, 0].hist(safety_scores, bins=20, alpha=0.7, color='orange')
    axes[1, 0].axvline(x=0.7, color='red', linestyle='--', label='Safety Threshold')
    axes[1, 0].set_xlabel('Safety Score')
    axes[1, 0].set_ylabel('Frequency')
    axes[1, 0].set_title('Brand Safety Score Distribution')
    axes[1, 0].legend()
    
    # 4. ì‚¬ê¸° ìœ„í—˜ë„ vs í´ë¦­ìœ¨
    click_rates = traffic_data['clicks'] / traffic_data['impressions']
    fraud_scores = np.random.uniform(0, 1, len(traffic_data))  # ì‹œë®¬ë ˆì´ì…˜
    
    axes[1, 1].scatter(click_rates, fraud_scores, alpha=0.6)
    axes[1, 1].set_xlabel('Click Rate')
    axes[1, 1].set_ylabel('Fraud Risk Score')
    axes[1, 1].set_title('Click Rate vs Fraud Risk')
    
    plt.tight_layout()
    plt.show()
    
    return {
        'programmatic_analysis': programmatic_analysis,
        'brand_safety_results': brand_safety_results,
        'fraud_detection_results': fraud_detection_results,
        'ecosystem_health_score': np.mean([
            np.mean(quality_scores),
            np.mean(safety_scores),
            1 - np.mean(fraud_scores)  # ë‚®ì€ ì‚¬ê¸° ìœ„í—˜ì´ ì¢‹ìŒ
        ])
    }

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    print("=== ë””ì§€í„¸ ê´‘ê³  ìƒíƒœê³„ ì‹¤ìŠµ ===")
    print("í”„ë¡œê·¸ë˜ë§¤í‹± ê´‘ê³ ì™€ ë¸Œëœë“œ ì„¸ì´í”„í‹° ë¶„ì„")
    
    results = comprehensive_digital_ecosystem_analysis()
    
    print(f"\nìƒíƒœê³„ ë¶„ì„ ì™„ë£Œ:")
    print(f"- ì „ì²´ ìƒíƒœê³„ ê±´ê°•ë„: {results['ecosystem_health_score']:.3f}")
    print(f"- í”„ë¡œê·¸ë˜ë§¤í‹± íš¨ìœ¨ì„±: ë¶„ì„ ì™„ë£Œ")
    print(f"- ë¸Œëœë“œ ì„¸ì´í”„í‹°: ëª¨ë‹ˆí„°ë§ í™œì„±í™”")
    print(f"- ì‚¬ê¸° íƒì§€: ì‹œìŠ¤í…œ ê°€ë™ ì¤‘")
```

## ğŸš€ í”„ë¡œì íŠ¸
1. **ì‹¤ì‹œê°„ RTB ìµœì í™” ì—”ì§„** - ì…ì°° ì „ëµ ìë™ ì¡°ì • ì‹œìŠ¤í…œ
2. **ë¸Œëœë“œ ì„¸ì´í”„í‹° AI ëª¨ë‹ˆí„°** - ì»¨í…ì¸  ìœ„í—˜ë„ ì‹¤ì‹œê°„ ë¶„ì„
3. **ê´‘ê³  ì‚¬ê¸° íƒì§€ í”Œë«í¼** - ML ê¸°ë°˜ ì´ìƒ íŒ¨í„´ íƒì§€
4. **í”„ë¼ì´ë²„ì‹œ ì»´í”Œë¼ì´ì–¸ìŠ¤ ë„êµ¬** - ì¿ í‚¤ë¦¬ìŠ¤ í™˜ê²½ ëŒ€ì‘ ì‹œìŠ¤í…œ