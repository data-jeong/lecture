# 24. Computer Vision - ì»´í“¨í„° ë¹„ì „

## ğŸ“š ê³¼ì • ì†Œê°œ
ê´‘ê³  í¬ë¦¬ì—ì´í‹°ë¸Œ ë¶„ì„, ìë™ ì´ë¯¸ì§€ íƒœê¹…, ë¸Œëœë“œ ë¡œê³  ì¸ì‹, ê´‘ê³  ì„±ê³¼ ì˜ˆì¸¡ì„ ìœ„í•œ ì»´í“¨í„° ë¹„ì „ ê¸°ìˆ ì„ ë§ˆìŠ¤í„°í•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- ê´‘ê³  ì´ë¯¸ì§€ ìë™ ë¶„ì„ ë° íƒœê¹…
- ë¸Œëœë“œ ë¡œê³  ì¸ì‹ ì‹œìŠ¤í…œ
- í¬ë¦¬ì—ì´í‹°ë¸Œ ì„±ê³¼ ì˜ˆì¸¡ ëª¨ë¸
- ì´ë¯¸ì§€ ê¸°ë°˜ íƒ€ê²ŸíŒ… ì‹œìŠ¤í…œ

## ğŸ“– ì£¼ìš” ë‚´ìš©

### ê´‘ê³  í¬ë¦¬ì—ì´í‹°ë¸Œ ë¶„ì„
```python
import cv2
import numpy as np
from tensorflow.keras.applications import ResNet50, VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
import torch
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt

class AdCreativeAnalyzer:
    """ê´‘ê³  í¬ë¦¬ì—ì´í‹°ë¸Œ ë¶„ì„ê¸°"""
    
    def __init__(self):
        # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
        self.resnet_model = ResNet50(weights='imagenet')
        self.feature_extractor = ResNet50(weights='imagenet', include_top=False, pooling='avg')
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
    
    def analyze_creative_elements(self, image_path: str) -> dict:
        """í¬ë¦¬ì—ì´í‹°ë¸Œ ìš”ì†Œ ë¶„ì„"""
        # ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(image_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # ë‹¤ì–‘í•œ ë¶„ì„ ìˆ˜í–‰
        analysis = {
            'color_analysis': self._analyze_colors(img_rgb),
            'object_detection': self._detect_objects(img_rgb),
            'text_detection': self._detect_text(img),
            'composition_analysis': self._analyze_composition(img_rgb),
            'emotional_tone': self._analyze_emotional_tone(img_rgb),
            'brand_elements': self._detect_brand_elements(img_rgb)
        }
        
        return analysis
    
    def _analyze_colors(self, img: np.ndarray) -> dict:
        """ìƒ‰ìƒ ë¶„ì„"""
        # ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ
        pixels = img.reshape(-1, 3)
        from sklearn.cluster import KMeans
        
        kmeans = KMeans(n_clusters=5, random_state=42)
        kmeans.fit(pixels)
        
        colors = kmeans.cluster_centers_.astype(int)
        percentages = np.bincount(kmeans.labels_) / len(kmeans.labels_)
        
        # ìƒ‰ìƒ ì˜¨ë„ ê³„ì‚°
        avg_color = np.mean(pixels, axis=0)
        color_temp = self._calculate_color_temperature(avg_color)
        
        # ì±„ë„ ë° ë°ê¸° ë¶„ì„
        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
        saturation = np.mean(hsv[:, :, 1])
        brightness = np.mean(hsv[:, :, 2])
        
        return {
            'dominant_colors': [tuple(color) for color in colors],
            'color_percentages': percentages.tolist(),
            'color_temperature': color_temp,
            'average_saturation': float(saturation),
            'average_brightness': float(brightness),
            'color_harmony': self._assess_color_harmony(colors)
        }
    
    def _detect_objects(self, img: np.ndarray) -> dict:
        """ê°ì²´ ê°ì§€"""
        # ResNetìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜
        img_resized = cv2.resize(img, (224, 224))
        img_array = np.expand_dims(img_resized, axis=0)
        img_preprocessed = preprocess_input(img_array)
        
        predictions = self.resnet_model.predict(img_preprocessed)
        decoded_predictions = decode_predictions(predictions, top=5)[0]
        
        detected_objects = []
        for _, class_name, confidence in decoded_predictions:
            detected_objects.append({
                'object': class_name,
                'confidence': float(confidence),
                'category': self._categorize_object(class_name)
            })
        
        return {
            'detected_objects': detected_objects,
            'main_subject': detected_objects[0]['object'] if detected_objects else None,
            'object_diversity': len(set([obj['category'] for obj in detected_objects]))
        }
    
    def _detect_text(self, img: np.ndarray) -> dict:
        """í…ìŠ¤íŠ¸ ê°ì§€ (OCR)"""
        import pytesseract
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # í…ìŠ¤íŠ¸ ì˜ì—­ ê°ì§€
        text_areas = pytesseract.image_to_boxes(gray)
        detected_text = pytesseract.image_to_string(gray, lang='kor+eng')
        
        # í…ìŠ¤íŠ¸ íŠ¹ì„± ë¶„ì„
        text_lines = [line.strip() for line in detected_text.split('\n') if line.strip()]
        
        return {
            'detected_text': detected_text,
            'text_lines': text_lines,
            'text_count': len(text_lines),
            'text_density': len(detected_text) / (img.shape[0] * img.shape[1]) * 10000,
            'has_call_to_action': self._detect_cta(detected_text),
            'language': self._detect_language(detected_text)
        }
    
    def _analyze_composition(self, img: np.ndarray) -> dict:
        """êµ¬ë„ ë¶„ì„"""
        h, w = img.shape[:2]
        
        # ì‚¼ë“±ë¶„í•  ë¶„ì„
        rule_of_thirds_score = self._calculate_rule_of_thirds(img)
        
        # ëŒ€ì¹­ì„± ë¶„ì„
        symmetry_score = self._calculate_symmetry(img)
        
        # ì‹œê°ì  ê· í˜• ë¶„ì„
        balance_score = self._calculate_visual_balance(img)
        
        # ì—¬ë°± ë¶„ì„
        whitespace_ratio = self._calculate_whitespace_ratio(img)
        
        return {
            'rule_of_thirds_score': rule_of_thirds_score,
            'symmetry_score': symmetry_score,
            'visual_balance': balance_score,
            'whitespace_ratio': whitespace_ratio,
            'aspect_ratio': w / h,
            'composition_quality': (rule_of_thirds_score + symmetry_score + balance_score) / 3
        }
    
    def _analyze_emotional_tone(self, img: np.ndarray) -> dict:
        """ê°ì •ì  í†¤ ë¶„ì„"""
        # ìƒ‰ìƒ ê¸°ë°˜ ê°ì • ë¶„ì„
        avg_color = np.mean(img.reshape(-1, 3), axis=0)
        
        # HSV ë³€í™˜ìœ¼ë¡œ ê°ì • í†¤ ë¶„ì„
        hsv_avg = cv2.cvtColor(np.uint8([[avg_color]]), cv2.COLOR_RGB2HSV)[0][0]
        
        emotions = {
            'warmth': self._calculate_warmth(avg_color),
            'energy': self._calculate_energy(hsv_avg),
            'professionalism': self._calculate_professionalism(img),
            'friendliness': self._calculate_friendliness(img),
            'trustworthiness': self._calculate_trustworthiness(img)
        }
        
        # ì£¼ìš” ê°ì • í†¤
        dominant_emotion = max(emotions, key=emotions.get)
        
        return {
            'emotional_scores': emotions,
            'dominant_emotion': dominant_emotion,
            'emotion_intensity': emotions[dominant_emotion],
            'emotional_balance': np.std(list(emotions.values()))
        }
    
    def _detect_brand_elements(self, img: np.ndarray) -> dict:
        """ë¸Œëœë“œ ìš”ì†Œ ê°ì§€"""
        # ë¡œê³  ê°ì§€ (í…œí”Œë¦¿ ë§¤ì¹­)
        logo_detected = self._detect_logos(img)
        
        # ë¸Œëœë“œ ìƒ‰ìƒ ê°ì§€
        brand_colors = self._detect_brand_colors(img)
        
        # í°íŠ¸ ìŠ¤íƒ€ì¼ ë¶„ì„
        font_analysis = self._analyze_fonts(img)
        
        return {
            'logo_detected': logo_detected,
            'brand_colors': brand_colors,
            'font_style': font_analysis,
            'brand_consistency': self._calculate_brand_consistency(logo_detected, brand_colors),
            'brand_visibility': self._calculate_brand_visibility(img)
        }

class CreativePerformancePredictor:
    """í¬ë¦¬ì—ì´í‹°ë¸Œ ì„±ê³¼ ì˜ˆì¸¡ê¸°"""
    
    def __init__(self):
        self.analyzer = AdCreativeAnalyzer()
        self.model = self._build_performance_model()
        
    def _build_performance_model(self):
        """ì„±ê³¼ ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¶•"""
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.preprocessing import StandardScaler
        
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” í›ˆë ¨ëœ ëª¨ë¸ì„ ë¡œë“œ
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        scaler = StandardScaler()
        
        return {'model': model, 'scaler': scaler}
    
    def predict_ctr(self, image_path: str, campaign_context: dict = None) -> dict:
        """CTR ì˜ˆì¸¡"""
        # í¬ë¦¬ì—ì´í‹°ë¸Œ ë¶„ì„
        analysis = self.analyzer.analyze_creative_elements(image_path)
        
        # íŠ¹ì„± ë²¡í„° ìƒì„±
        features = self._extract_features(analysis, campaign_context)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰ (ì‹¤ì œë¡œëŠ” í›ˆë ¨ëœ ëª¨ë¸ ì‚¬ìš©)
        predicted_ctr = self._mock_prediction(features)
        
        # ê°œì„  ì œì•ˆ
        improvements = self._suggest_improvements(analysis, predicted_ctr)
        
        return {
            'predicted_ctr': predicted_ctr,
            'confidence': 0.85,  # ëª¨ë¸ ì‹ ë¢°ë„
            'performance_factors': self._identify_performance_factors(analysis),
            'improvement_suggestions': improvements,
            'benchmark_comparison': self._compare_with_benchmark(analysis)
        }
    
    def _extract_features(self, analysis: dict, context: dict = None) -> np.ndarray:
        """íŠ¹ì„± ë²¡í„° ì¶”ì¶œ"""
        features = []
        
        # ìƒ‰ìƒ íŠ¹ì„±
        color_features = [
            analysis['color_analysis']['average_saturation'],
            analysis['color_analysis']['average_brightness'],
            analysis['color_analysis']['color_temperature']
        ]
        features.extend(color_features)
        
        # êµ¬ë„ íŠ¹ì„±
        composition_features = [
            analysis['composition_analysis']['rule_of_thirds_score'],
            analysis['composition_analysis']['symmetry_score'],
            analysis['composition_analysis']['visual_balance'],
            analysis['composition_analysis']['whitespace_ratio']
        ]
        features.extend(composition_features)
        
        # í…ìŠ¤íŠ¸ íŠ¹ì„±
        text_features = [
            analysis['text_detection']['text_count'],
            analysis['text_detection']['text_density'],
            1 if analysis['text_detection']['has_call_to_action'] else 0
        ]
        features.extend(text_features)
        
        # ê°ì • íŠ¹ì„±
        emotion_features = list(analysis['emotional_tone']['emotional_scores'].values())
        features.extend(emotion_features)
        
        # ë¸Œëœë“œ íŠ¹ì„±
        brand_features = [
            1 if analysis['brand_elements']['logo_detected'] else 0,
            analysis['brand_elements']['brand_consistency'],
            analysis['brand_elements']['brand_visibility']
        ]
        features.extend(brand_features)
        
        # ì»¨í…ìŠ¤íŠ¸ íŠ¹ì„± (ìº í˜ì¸ ì •ë³´)
        if context:
            context_features = [
                context.get('target_age_group', 25) / 100,  # ì •ê·œí™”
                1 if context.get('device_type') == 'mobile' else 0,
                context.get('time_of_day', 12) / 24  # ì •ê·œí™”
            ]
            features.extend(context_features)
        
        return np.array(features)
    
    def _mock_prediction(self, features: np.ndarray) -> float:
        """ëª¨ì˜ ì˜ˆì¸¡ (ì‹¤ì œë¡œëŠ” í›ˆë ¨ëœ ëª¨ë¸ ì‚¬ìš©)"""
        # íŠ¹ì„± ê¸°ë°˜ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±
        base_ctr = 0.02
        
        # ìƒ‰ìƒ íš¨ê³¼
        if len(features) > 2 and features[1] > 0.7:  # ë†’ì€ ë°ê¸°
            base_ctr *= 1.1
        
        # êµ¬ë„ íš¨ê³¼
        if len(features) > 5 and features[3] > 0.6:  # ì¢‹ì€ êµ¬ë„
            base_ctr *= 1.15
        
        # í…ìŠ¤íŠ¸ íš¨ê³¼
        if len(features) > 8 and features[8] > 0:  # CTA ì¡´ì¬
            base_ctr *= 1.2
        
        # ë¸Œëœë“œ íš¨ê³¼
        if len(features) > 15 and features[15] > 0:  # ë¡œê³  ì¡´ì¬
            base_ctr *= 1.05
        
        return min(base_ctr, 0.15)  # ìµœëŒ€ 15% CTR
    
    def _suggest_improvements(self, analysis: dict, predicted_ctr: float) -> list:
        """ê°œì„  ì œì•ˆ"""
        suggestions = []
        
        # ìƒ‰ìƒ ê°œì„ 
        if analysis['color_analysis']['average_saturation'] < 0.3:
            suggestions.append({
                'category': 'color',
                'suggestion': 'ìƒ‰ìƒ ì±„ë„ë¥¼ ë†’ì—¬ ì‹œê°ì  ì„íŒ©íŠ¸ë¥¼ ì¦ê°€ì‹œí‚¤ì„¸ìš”',
                'impact': 'medium'
            })
        
        # êµ¬ë„ ê°œì„ 
        if analysis['composition_analysis']['rule_of_thirds_score'] < 0.4:
            suggestions.append({
                'category': 'composition',
                'suggestion': 'ì‚¼ë“±ë¶„í• ì˜ ë²•ì¹™ì„ í™œìš©í•´ êµ¬ë„ë¥¼ ê°œì„ í•˜ì„¸ìš”',
                'impact': 'high'
            })
        
        # í…ìŠ¤íŠ¸ ê°œì„ 
        if not analysis['text_detection']['has_call_to_action']:
            suggestions.append({
                'category': 'text',
                'suggestion': 'ëª…í™•í•œ í–‰ë™ ìœ ë„ ë¬¸êµ¬(CTA)ë¥¼ ì¶”ê°€í•˜ì„¸ìš”',
                'impact': 'high'
            })
        
        # ë¸Œëœë“œ ê°œì„ 
        if not analysis['brand_elements']['logo_detected']:
            suggestions.append({
                'category': 'brand',
                'suggestion': 'ë¸Œëœë“œ ë¡œê³ ë¥¼ ì¶”ê°€í•˜ì—¬ ì¸ì§€ë„ë¥¼ ë†’ì´ì„¸ìš”',
                'impact': 'medium'
            })
        
        return suggestions

class BrandLogoRecognizer:
    """ë¸Œëœë“œ ë¡œê³  ì¸ì‹ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.logo_templates = self._load_logo_templates()
        self.feature_matcher = cv2.SIFT_create()
        
    def _load_logo_templates(self) -> dict:
        """ë¡œê³  í…œí”Œë¦¿ ë¡œë“œ"""
        # ì‹¤ì œë¡œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ íŒŒì¼ì—ì„œ ë¡œë“œ
        return {
            'nike': 'path/to/nike_logo.png',
            'adidas': 'path/to/adidas_logo.png',
            'coca_cola': 'path/to/cocacola_logo.png'
        }
    
    def recognize_logos(self, image_path: str) -> list:
        """ë¡œê³  ì¸ì‹"""
        img = cv2.imread(image_path)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        detected_logos = []
        
        for brand, template_path in self.logo_templates.items():
            if self._template_exists(template_path):
                confidence, location = self._match_template(gray, template_path)
                
                if confidence > 0.7:  # ì„ê³„ê°’
                    detected_logos.append({
                        'brand': brand,
                        'confidence': confidence,
                        'location': location,
                        'size': self._calculate_logo_size(location)
                    })
        
        return sorted(detected_logos, key=lambda x: x['confidence'], reverse=True)
    
    def _match_template(self, img: np.ndarray, template_path: str) -> tuple:
        """í…œí”Œë¦¿ ë§¤ì¹­"""
        template = cv2.imread(template_path, 0)
        
        # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ë§¤ì¹­
        best_confidence = 0
        best_location = None
        
        for scale in np.linspace(0.2, 3.0, 20):
            resized_template = cv2.resize(template, None, fx=scale, fy=scale)
            
            if resized_template.shape[0] > img.shape[0] or resized_template.shape[1] > img.shape[1]:
                continue
            
            result = cv2.matchTemplate(img, resized_template, cv2.TM_CCOEFF_NORMED)
            _, max_val, _, max_loc = cv2.minMaxLoc(result)
            
            if max_val > best_confidence:
                best_confidence = max_val
                best_location = {
                    'x': max_loc[0],
                    'y': max_loc[1],
                    'width': resized_template.shape[1],
                    'height': resized_template.shape[0]
                }
        
        return best_confidence, best_location

class ImageBasedTargeting:
    """ì´ë¯¸ì§€ ê¸°ë°˜ íƒ€ê²ŸíŒ… ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.analyzer = AdCreativeAnalyzer()
        self.audience_profiles = self._load_audience_profiles()
        
    def _load_audience_profiles(self) -> dict:
        """ì˜¤ë””ì–¸ìŠ¤ í”„ë¡œí•„ ë¡œë“œ"""
        return {
            'young_professionals': {
                'preferred_colors': ['blue', 'gray', 'white'],
                'style_keywords': ['modern', 'clean', 'professional'],
                'emotional_tone': ['professionalism', 'trustworthiness']
            },
            'millennials': {
                'preferred_colors': ['bright', 'vibrant'],
                'style_keywords': ['trendy', 'social', 'authentic'],
                'emotional_tone': ['energy', 'friendliness']
            },
            'luxury_consumers': {
                'preferred_colors': ['black', 'gold', 'white'],
                'style_keywords': ['elegant', 'premium', 'exclusive'],
                'emotional_tone': ['professionalism', 'trustworthiness']
            }
        }
    
    def predict_audience_fit(self, image_path: str) -> dict:
        """ì´ë¯¸ì§€-ì˜¤ë””ì–¸ìŠ¤ ì í•©ë„ ì˜ˆì¸¡"""
        analysis = self.analyzer.analyze_creative_elements(image_path)
        
        audience_scores = {}
        
        for audience, profile in self.audience_profiles.items():
            score = self._calculate_fit_score(analysis, profile)
            audience_scores[audience] = score
        
        # ìµœì  ì˜¤ë””ì–¸ìŠ¤ ì„ íƒ
        best_audience = max(audience_scores, key=audience_scores.get)
        
        return {
            'audience_scores': audience_scores,
            'recommended_audience': best_audience,
            'confidence': audience_scores[best_audience],
            'targeting_suggestions': self._generate_targeting_suggestions(analysis, best_audience)
        }
    
    def _calculate_fit_score(self, analysis: dict, profile: dict) -> float:
        """ì í•©ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # ìƒ‰ìƒ ë§¤ì¹­
        dominant_colors = analysis['color_analysis']['dominant_colors']
        color_match = self._match_colors(dominant_colors, profile['preferred_colors'])
        score += color_match * 0.3
        
        # ê°ì • í†¤ ë§¤ì¹­
        emotional_scores = analysis['emotional_tone']['emotional_scores']
        emotion_match = self._match_emotions(emotional_scores, profile['emotional_tone'])
        score += emotion_match * 0.4
        
        # êµ¬ë„ í’ˆì§ˆ
        composition_quality = analysis['composition_analysis']['composition_quality']
        score += composition_quality * 0.3
        
        return min(score, 1.0)
```

## ğŸš€ í”„ë¡œì íŠ¸
1. **AI í¬ë¦¬ì—ì´í‹°ë¸Œ ë¶„ì„ í”Œë«í¼**
2. **ë¸Œëœë“œ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ**
3. **ìë™ ì´ë¯¸ì§€ íƒœê¹… ë° ë¶„ë¥˜**
4. **ì„±ê³¼ ì˜ˆì¸¡ ê¸°ë°˜ í¬ë¦¬ì—ì´í‹°ë¸Œ ìµœì í™”**