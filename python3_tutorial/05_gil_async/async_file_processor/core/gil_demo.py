"""
GIL(Global Interpreter Lock) ë°ëª¨
GILì˜ ì˜í–¥ì„ ì‹œê°ì ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ” ì˜ˆì œ
"""

import time
import threading
import multiprocessing
from typing import List, Tuple, Callable, Any
import concurrent.futures
import asyncio
import aiohttp
from dataclasses import dataclass
import json


@dataclass
class BenchmarkResult:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼"""
    name: str
    duration: float
    speedup: float = 1.0
    
    def __str__(self) -> str:
        return f"{self.name}: {self.duration:.2f}ì´ˆ (ì†ë„í–¥ìƒ: {self.speedup:.2f}x)"


class GILDemo:
    """GIL ë°ëª¨ í´ë˜ìŠ¤"""
    
    def __init__(self, task_size: int = 10_000_000):
        self.task_size = task_size
        self.results: List[BenchmarkResult] = []
    
    def cpu_bound_task(self, n: int) -> int:
        """CPU ì§‘ì•½ì  ì‘ì—…"""
        result = 0
        for i in range(n):
            result += i ** 2
        return result
    
    def io_bound_task(self, delay: float) -> str:
        """I/O ì§‘ì•½ì  ì‘ì—… (ì‹œë®¬ë ˆì´ì…˜)"""
        time.sleep(delay)
        return f"Slept for {delay} seconds"
    
    async def async_io_task(self, url: str) -> int:
        """ë¹„ë™ê¸° I/O ì‘ì—…"""
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get(url, timeout=5) as response:
                    return len(await response.text())
            except Exception as e:
                print(f"Error fetching {url}: {e}")
                return 0
    
    def benchmark_single_thread(self) -> BenchmarkResult:
        """ë‹¨ì¼ ìŠ¤ë ˆë“œ ë²¤ì¹˜ë§ˆí¬"""
        print("\nğŸ”¹ ë‹¨ì¼ ìŠ¤ë ˆë“œ í…ŒìŠ¤íŠ¸...")
        start = time.perf_counter()
        
        # ë‘ ë²ˆì˜ CPU ì‘ì—… ìˆœì°¨ ì‹¤í–‰
        self.cpu_bound_task(self.task_size)
        self.cpu_bound_task(self.task_size)
        
        duration = time.perf_counter() - start
        result = BenchmarkResult("ë‹¨ì¼ ìŠ¤ë ˆë“œ", duration)
        self.results.append(result)
        return result
    
    def benchmark_multi_thread(self) -> BenchmarkResult:
        """ë©€í‹° ìŠ¤ë ˆë“œ ë²¤ì¹˜ë§ˆí¬"""
        print("\nğŸ”¹ ë©€í‹° ìŠ¤ë ˆë“œ í…ŒìŠ¤íŠ¸...")
        start = time.perf_counter()
        
        threads = []
        for _ in range(2):
            t = threading.Thread(
                target=self.cpu_bound_task, 
                args=(self.task_size,)
            )
            t.start()
            threads.append(t)
        
        for t in threads:
            t.join()
        
        duration = time.perf_counter() - start
        speedup = self.results[0].duration / duration if self.results else 1.0
        result = BenchmarkResult("ë©€í‹° ìŠ¤ë ˆë“œ", duration, speedup)
        self.results.append(result)
        return result
    
    def benchmark_multi_process(self) -> BenchmarkResult:
        """ë©€í‹° í”„ë¡œì„¸ìŠ¤ ë²¤ì¹˜ë§ˆí¬"""
        print("\nğŸ”¹ ë©€í‹° í”„ë¡œì„¸ìŠ¤ í…ŒìŠ¤íŠ¸...")
        start = time.perf_counter()
        
        with multiprocessing.Pool(2) as pool:
            pool.map(self.cpu_bound_task, [self.task_size, self.task_size])
        
        duration = time.perf_counter() - start
        speedup = self.results[0].duration / duration if self.results else 1.0
        result = BenchmarkResult("ë©€í‹° í”„ë¡œì„¸ìŠ¤", duration, speedup)
        self.results.append(result)
        return result
    
    def benchmark_thread_pool(self) -> BenchmarkResult:
        """ìŠ¤ë ˆë“œ í’€ ë²¤ì¹˜ë§ˆí¬"""
        print("\nğŸ”¹ ìŠ¤ë ˆë“œ í’€ í…ŒìŠ¤íŠ¸...")
        start = time.perf_counter()
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            futures = [
                executor.submit(self.cpu_bound_task, self.task_size)
                for _ in range(2)
            ]
            concurrent.futures.wait(futures)
        
        duration = time.perf_counter() - start
        speedup = self.results[0].duration / duration if self.results else 1.0
        result = BenchmarkResult("ìŠ¤ë ˆë“œ í’€", duration, speedup)
        self.results.append(result)
        return result
    
    def benchmark_process_pool(self) -> BenchmarkResult:
        """í”„ë¡œì„¸ìŠ¤ í’€ ë²¤ì¹˜ë§ˆí¬"""
        print("\nğŸ”¹ í”„ë¡œì„¸ìŠ¤ í’€ í…ŒìŠ¤íŠ¸...")
        start = time.perf_counter()
        
        with concurrent.futures.ProcessPoolExecutor(max_workers=2) as executor:
            futures = [
                executor.submit(self.cpu_bound_task, self.task_size)
                for _ in range(2)
            ]
            concurrent.futures.wait(futures)
        
        duration = time.perf_counter() - start
        speedup = self.results[0].duration / duration if self.results else 1.0
        result = BenchmarkResult("í”„ë¡œì„¸ìŠ¤ í’€", duration, speedup)
        self.results.append(result)
        return result
    
    async def benchmark_async_io(self) -> BenchmarkResult:
        """ë¹„ë™ê¸° I/O ë²¤ì¹˜ë§ˆí¬"""
        print("\nğŸ”¹ ë¹„ë™ê¸° I/O í…ŒìŠ¤íŠ¸...")
        
        urls = [
            "https://httpbin.org/delay/1",
            "https://httpbin.org/delay/1",
            "https://httpbin.org/delay/1",
            "https://httpbin.org/delay/1",
        ]
        
        # ë™ê¸° ë°©ì‹
        print("  - ë™ê¸° ë°©ì‹ í…ŒìŠ¤íŠ¸...")
        start = time.perf_counter()
        for _ in urls:
            self.io_bound_task(1.0)
        sync_duration = time.perf_counter() - start
        
        # ë¹„ë™ê¸° ë°©ì‹
        print("  - ë¹„ë™ê¸° ë°©ì‹ í…ŒìŠ¤íŠ¸...")
        start = time.perf_counter()
        tasks = [self.async_io_task(url) for url in urls]
        await asyncio.gather(*tasks)
        async_duration = time.perf_counter() - start
        
        speedup = sync_duration / async_duration
        result = BenchmarkResult(
            f"ë¹„ë™ê¸° I/O ({len(urls)}ê°œ ìš”ì²­)", 
            async_duration, 
            speedup
        )
        return result
    
    def run_all_benchmarks(self) -> None:
        """ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print(f"\nğŸš€ GIL ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ (ì‘ì—… í¬ê¸°: {self.task_size:,})")
        print("=" * 60)
        
        # CPU ì§‘ì•½ì  ì‘ì—… ë²¤ì¹˜ë§ˆí¬
        self.benchmark_single_thread()
        self.benchmark_multi_thread()
        self.benchmark_multi_process()
        self.benchmark_thread_pool()
        self.benchmark_process_pool()
        
        # ê²°ê³¼ ì¶œë ¥
        self.print_results()
    
    def print_results(self) -> None:
        """ê²°ê³¼ ì¶œë ¥"""
        print("\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼")
        print("=" * 60)
        
        baseline = self.results[0].duration if self.results else 1.0
        
        for result in self.results:
            speedup_bar = "â–ˆ" * int(result.speedup * 10)
            print(f"{result.name:15} | {result.duration:6.2f}ì´ˆ | "
                  f"ì†ë„í–¥ìƒ: {result.speedup:4.2f}x {speedup_bar}")
        
        print("\nğŸ’¡ GIL ì˜í–¥ ë¶„ì„:")
        
        # GIL ì˜í–¥ ê³„ì‚°
        thread_result = next((r for r in self.results if "ë©€í‹° ìŠ¤ë ˆë“œ" in r.name), None)
        process_result = next((r for r in self.results if "ë©€í‹° í”„ë¡œì„¸ìŠ¤" in r.name), None)
        
        if thread_result and process_result:
            gil_impact = (thread_result.duration - process_result.duration) / thread_result.duration * 100
            print(f"- GILë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜: {gil_impact:.1f}%")
            print(f"- ë©€í‹°í”„ë¡œì„¸ì‹± íš¨ìœ¨: {process_result.speedup:.1f}x")
            
            if gil_impact > 50:
                print("- ê¶Œì¥ì‚¬í•­: CPU ì§‘ì•½ì  ì‘ì—…ì—ëŠ” multiprocessing ì‚¬ìš©")
            else:
                print("- ê¶Œì¥ì‚¬í•­: I/O ì§‘ì•½ì  ì‘ì—…ì—ëŠ” threading ë˜ëŠ” asyncio ì‚¬ìš©")
    
    def save_results(self, filename: str = "gil_benchmark_results.json") -> None:
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        data = {
            "task_size": self.task_size,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "results": [
                {
                    "name": r.name,
                    "duration": r.duration,
                    "speedup": r.speedup
                }
                for r in self.results
            ]
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def measure_gil_impact(task_size: int = 5_000_000) -> dict:
    """GIL ì˜í–¥ ì¸¡ì • í•¨ìˆ˜"""
    demo = GILDemo(task_size)
    demo.run_all_benchmarks()
    
    # ê²°ê³¼ ë°˜í™˜
    return {
        result.name: {
            "duration": result.duration,
            "speedup": result.speedup
        }
        for result in demo.results
    }


def demonstrate_gil_with_io():
    """I/O ì‘ì—…ì—ì„œì˜ GIL ì˜í–¥ ë°ëª¨"""
    print("\nğŸŒ I/O ì‘ì—…ì—ì„œì˜ GIL ì˜í–¥ ë°ëª¨")
    print("=" * 60)
    
    def io_task(n: int) -> str:
        """I/O ì‹œë®¬ë ˆì´ì…˜"""
        time.sleep(0.1)  # I/O ëŒ€ê¸° ì‹œë®¬ë ˆì´ì…˜
        return f"Task {n} completed"
    
    # ìˆœì°¨ ì‹¤í–‰
    print("\n1. ìˆœì°¨ ì‹¤í–‰ (4ê°œ ì‘ì—…):")
    start = time.perf_counter()
    for i in range(4):
        io_task(i)
    sequential_time = time.perf_counter() - start
    print(f"   ì†Œìš” ì‹œê°„: {sequential_time:.2f}ì´ˆ")
    
    # ìŠ¤ë ˆë“œ ì‹¤í–‰
    print("\n2. ìŠ¤ë ˆë“œ ì‹¤í–‰ (4ê°œ ì‘ì—…):")
    start = time.perf_counter()
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(io_task, i) for i in range(4)]
        concurrent.futures.wait(futures)
    threaded_time = time.perf_counter() - start
    print(f"   ì†Œìš” ì‹œê°„: {threaded_time:.2f}ì´ˆ")
    print(f"   ì†ë„ í–¥ìƒ: {sequential_time / threaded_time:.2f}x")
    
    print("\nğŸ’¡ ê²°ë¡ : I/O ì‘ì—…ì—ì„œëŠ” GILì´ í•´ì œë˜ì–´ ë©€í‹°ìŠ¤ë ˆë”©ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤!")


if __name__ == "__main__":
    # GIL ì˜í–¥ ì¸¡ì •
    print("ğŸ”¬ Python GIL(Global Interpreter Lock) ë°ëª¨")
    print("=" * 60)
    
    # CPU ì§‘ì•½ì  ì‘ì—…ì—ì„œì˜ GIL ì˜í–¥
    results = measure_gil_impact()
    
    # I/O ì‘ì—…ì—ì„œì˜ GIL ì˜í–¥
    demonstrate_gil_with_io()
    
    # ë¹„ë™ê¸° I/O ë°ëª¨
    print("\nğŸ”„ ë¹„ë™ê¸° I/O ë°ëª¨")
    async def async_demo():
        demo = GILDemo()
        result = await demo.benchmark_async_io()
        print(f"\n{result}")
    
    asyncio.run(async_demo())