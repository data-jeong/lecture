#!/usr/bin/env python3
"""
ë¹„ë™ê¸° íŒŒì¼ ì²˜ë¦¬ê¸° CLI
GIL, ë¹„ë™ê¸°, ìŠ¤ë ˆë“œ, í”„ë¡œì„¸ìŠ¤ ì²˜ë¦¬ ë°©ì‹ ë¹„êµ ë° ì‹¤í–‰
"""

import asyncio
import argparse
import sys
import time
from pathlib import Path
from typing import List, Optional
import json

from core.gil_demo import GILDemo
from core.async_processor import AsyncProcessor
from core.thread_processor import ThreadProcessor
from core.process_processor import ProcessProcessor
from utils.monitoring import Monitor, PerformanceTracker
from patterns.rate_limiter import AsyncRateLimiter
from patterns.batch_processor import AsyncBatchProcessor
from examples.web_scraper import WebScraperExample
from examples.image_processor import ImageProcessorExample
from examples.log_analyzer import LogAnalyzerExample


class FileProcessorCLI:
    """íŒŒì¼ ì²˜ë¦¬ê¸° CLI"""
    
    def __init__(self):
        self.monitor = Monitor()
        self.tracker = PerformanceTracker()
    
    def run_gil_demo(self, args):
        """GIL ë°ëª¨ ì‹¤í–‰"""
        print("ğŸ” GIL (Global Interpreter Lock) ë°ëª¨")
        print("=" * 60)
        
        demo = GILDemo(task_size=args.task_size)
        
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        if args.monitor:
            self.monitor.start()
        
        # ê° ë°©ì‹ í…ŒìŠ¤íŠ¸
        results = []
        
        with self.tracker.track("GIL Demo - Single Thread"):
            result = demo.benchmark_single_thread()
            results.append(("ë‹¨ì¼ ìŠ¤ë ˆë“œ", result))
        
        with self.tracker.track("GIL Demo - Multi Thread"):
            result = demo.benchmark_multi_thread()
            results.append(("ë©€í‹° ìŠ¤ë ˆë“œ", result))
        
        with self.tracker.track("GIL Demo - Multi Process"):
            result = demo.benchmark_multi_process()
            results.append(("ë©€í‹° í”„ë¡œì„¸ìŠ¤", result))
        
        with self.tracker.track("GIL Demo - Async"):
            result = demo.benchmark_async()
            results.append(("ë¹„ë™ê¸°", result))
        
        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
        print("-" * 50)
        for name, result in results:
            print(f"\n{name}:")
            print(f"  ì‹¤í–‰ ì‹œê°„: {result.execution_time:.4f}ì´ˆ")
            print(f"  CPU ì‚¬ìš©ë¥ : {result.cpu_usage:.1f}%")
            print(f"  ì‘ì—… ìœ í˜•: {result.task_type}")
        
        # ëª¨ë‹ˆí„°ë§ ê²°ê³¼
        if args.monitor:
            self.monitor.stop()
            self.monitor.print_summary()
        
        # ì„±ëŠ¥ ë¦¬í¬íŠ¸
        self.tracker.print_report()
        
        if args.save_report:
            self.tracker.save_report("gil_demo_report.json")
            if args.monitor:
                self.monitor.save_history("gil_demo_monitor.json")
    
    async def run_async_processor(self, args):
        """ë¹„ë™ê¸° ì²˜ë¦¬ê¸° ì‹¤í–‰"""
        print("âš¡ ë¹„ë™ê¸° íŒŒì¼ ì²˜ë¦¬ê¸°")
        print("=" * 60)
        
        processor = AsyncProcessor(
            max_concurrent=args.max_concurrent,
            timeout=args.timeout
        )
        
        # íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        files = self._get_files(args.path, args.pattern)
        if not files:
            print("ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ì²˜ë¦¬í•  íŒŒì¼: {len(files)}ê°œ")
        
        # ì²˜ë¦¬ í•¨ìˆ˜ ì„ íƒ
        if args.process_type == "count":
            process_func = lambda content: len(content.split())
        elif args.process_type == "lines":
            process_func = lambda content: len(content.splitlines())
        else:
            process_func = lambda content: len(content)
        
        # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
        if args.batch_size:
            batch_processor = AsyncBatchProcessor(
                batch_size=args.batch_size,
                max_concurrent_batches=3
            )
            
            # ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
            async def batch_func(file_batch):
                results = []
                for file_path in file_batch:
                    result = await processor.process_file(str(file_path), process_func)
                    results.append(result)
                return results
            
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
            batch_results = await batch_processor.add_many(files, batch_func)
            
            # ê²°ê³¼ í‰íƒ„í™”
            results = []
            for batch_result in batch_results:
                if batch_result.results:
                    results.extend(batch_result.results)
        else:
            # ì¼ë°˜ ì²˜ë¦¬
            results = await processor.process_files(
                [str(f) for f in files],
                process_func
            )
        
        # ê²°ê³¼ ì¶œë ¥
        successful = [r for r in results if r.success]
        failed = [r for r in results if not r.success]
        
        print(f"\nâœ… ì„±ê³µ: {len(successful)}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {len(failed)}ê°œ")
        
        if failed and args.verbose:
            print("\nì‹¤íŒ¨í•œ íŒŒì¼:")
            for result in failed:
                print(f"  - {result.file_path}: {result.error}")
        
        # í†µê³„
        if successful:
            total_time = sum(r.processing_time for r in successful)
            avg_time = total_time / len(successful)
            print(f"\ní‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.4f}ì´ˆ/íŒŒì¼")
    
    def run_thread_processor(self, args):
        """ìŠ¤ë ˆë“œ ì²˜ë¦¬ê¸° ì‹¤í–‰"""
        print("ğŸ§µ ìŠ¤ë ˆë“œ ê¸°ë°˜ íŒŒì¼ ì²˜ë¦¬ê¸°")
        print("=" * 60)
        
        processor = ThreadProcessor(max_workers=args.max_workers)
        
        # íŒŒì¼ ëª©ë¡
        files = self._get_files(args.path, args.pattern)
        if not files:
            print("ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ì²˜ë¦¬í•  íŒŒì¼: {len(files)}ê°œ (ì›Œì»¤: {args.max_workers}ê°œ)")
        
        # ì²˜ë¦¬ í•¨ìˆ˜
        def process_func(content):
            # CPU ì§‘ì•½ì  ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            import hashlib
            for _ in range(100):
                hashlib.sha256(content.encode()).hexdigest()
            return len(content)
        
        # ì²˜ë¦¬ ì‹¤í–‰
        start_time = time.time()
        results = processor.process_files([str(f) for f in files], process_func)
        duration = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        successful = sum(1 for r in results if r.success)
        print(f"\nâœ… ì„±ê³µ: {successful}/{len(results)}ê°œ")
        print(f"â±ï¸  ì´ ì‹œê°„: {duration:.2f}ì´ˆ")
        
        # í†µê³„
        stats = processor.get_statistics()
        print("\nğŸ“Š í†µê³„:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
    
    def run_process_processor(self, args):
        """í”„ë¡œì„¸ìŠ¤ ì²˜ë¦¬ê¸° ì‹¤í–‰"""
        print("ğŸ”§ í”„ë¡œì„¸ìŠ¤ ê¸°ë°˜ íŒŒì¼ ì²˜ë¦¬ê¸°")
        print("=" * 60)
        
        processor = ProcessProcessor(max_workers=args.max_workers)
        
        # íŒŒì¼ ëª©ë¡
        files = self._get_files(args.path, args.pattern)
        if not files:
            print("ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ì²˜ë¦¬í•  íŒŒì¼: {len(files)}ê°œ (í”„ë¡œì„¸ìŠ¤: {args.max_workers}ê°œ)")
        
        # ì²˜ë¦¬ ì‹¤í–‰
        start_time = time.time()
        results = processor.process_files_parallel([str(f) for f in files])
        duration = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        successful = sum(1 for r in results if r["success"])
        print(f"\nâœ… ì„±ê³µ: {successful}/{len(results)}ê°œ")
        print(f"â±ï¸  ì´ ì‹œê°„: {duration:.2f}ì´ˆ")
    
    async def run_examples(self, args):
        """ì˜ˆì œ ì‹¤í–‰"""
        print("ğŸ“š ì˜ˆì œ ì‹¤í–‰")
        print("=" * 60)
        
        if args.example == "web":
            example = WebScraperExample()
            await example.run()
        
        elif args.example == "image":
            example = ImageProcessorExample()
            await example.run()
        
        elif args.example == "log":
            example = LogAnalyzerExample()
            await example.run()
        
        elif args.example == "all":
            print("\n1. ì›¹ ìŠ¤í¬ë˜í¼ ì˜ˆì œ")
            web_example = WebScraperExample()
            await web_example.run()
            
            print("\n\n2. ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜ˆì œ")
            image_example = ImageProcessorExample()
            await image_example.run()
            
            print("\n\n3. ë¡œê·¸ ë¶„ì„ ì˜ˆì œ")
            log_example = LogAnalyzerExample()
            await log_example.run()
    
    def _get_files(self, path: str, pattern: str) -> List[Path]:
        """íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        path = Path(path)
        
        if path.is_file():
            return [path]
        elif path.is_dir():
            return list(path.glob(pattern))
        else:
            return []
    
    def main(self):
        """ë©”ì¸ ì‹¤í–‰"""
        parser = argparse.ArgumentParser(
            description="ë¹„ë™ê¸° íŒŒì¼ ì²˜ë¦¬ê¸° - GIL, ë¹„ë™ê¸°, ìŠ¤ë ˆë“œ, í”„ë¡œì„¸ìŠ¤ ë¹„êµ"
        )
        
        subparsers = parser.add_subparsers(dest="command", help="ì‹¤í–‰í•  ëª…ë ¹")
        
        # GIL ë°ëª¨
        gil_parser = subparsers.add_parser("gil-demo", help="GIL ë°ëª¨ ì‹¤í–‰")
        gil_parser.add_argument("--task-size", type=int, default=1000000,
                              help="ì‘ì—… í¬ê¸°")
        gil_parser.add_argument("--monitor", action="store_true",
                              help="ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§")
        gil_parser.add_argument("--save-report", action="store_true",
                              help="ë¦¬í¬íŠ¸ ì €ì¥")
        
        # ë¹„ë™ê¸° ì²˜ë¦¬
        async_parser = subparsers.add_parser("async", help="ë¹„ë™ê¸° ì²˜ë¦¬")
        async_parser.add_argument("path", help="íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ")
        async_parser.add_argument("--pattern", default="*.txt",
                                help="íŒŒì¼ íŒ¨í„´")
        async_parser.add_argument("--max-concurrent", type=int, default=10,
                                help="ìµœëŒ€ ë™ì‹œ ì‹¤í–‰ ìˆ˜")
        async_parser.add_argument("--timeout", type=float, default=30.0,
                                help="íƒ€ì„ì•„ì›ƒ (ì´ˆ)")
        async_parser.add_argument("--process-type", 
                                choices=["size", "count", "lines"],
                                default="size",
                                help="ì²˜ë¦¬ ìœ í˜•")
        async_parser.add_argument("--batch-size", type=int,
                                help="ë°°ì¹˜ í¬ê¸°")
        async_parser.add_argument("--verbose", action="store_true",
                                help="ìƒì„¸ ì¶œë ¥")
        
        # ìŠ¤ë ˆë“œ ì²˜ë¦¬
        thread_parser = subparsers.add_parser("thread", help="ìŠ¤ë ˆë“œ ì²˜ë¦¬")
        thread_parser.add_argument("path", help="íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ")
        thread_parser.add_argument("--pattern", default="*.txt",
                                 help="íŒŒì¼ íŒ¨í„´")
        thread_parser.add_argument("--max-workers", type=int, default=4,
                                 help="ìµœëŒ€ ì›Œì»¤ ìˆ˜")
        
        # í”„ë¡œì„¸ìŠ¤ ì²˜ë¦¬
        process_parser = subparsers.add_parser("process", help="í”„ë¡œì„¸ìŠ¤ ì²˜ë¦¬")
        process_parser.add_argument("path", help="íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ")
        process_parser.add_argument("--pattern", default="*.txt",
                                  help="íŒŒì¼ íŒ¨í„´")
        process_parser.add_argument("--max-workers", type=int, default=4,
                                  help="ìµœëŒ€ í”„ë¡œì„¸ìŠ¤ ìˆ˜")
        
        # ì˜ˆì œ
        example_parser = subparsers.add_parser("example", help="ì˜ˆì œ ì‹¤í–‰")
        example_parser.add_argument("example",
                                  choices=["web", "image", "log", "all"],
                                  help="ì‹¤í–‰í•  ì˜ˆì œ")
        
        args = parser.parse_args()
        
        if not args.command:
            parser.print_help()
            return
        
        # ëª…ë ¹ ì‹¤í–‰
        if args.command == "gil-demo":
            self.run_gil_demo(args)
        
        elif args.command == "async":
            asyncio.run(self.run_async_processor(args))
        
        elif args.command == "thread":
            self.run_thread_processor(args)
        
        elif args.command == "process":
            self.run_process_processor(args)
        
        elif args.command == "example":
            asyncio.run(self.run_examples(args))


if __name__ == "__main__":
    cli = FileProcessorCLI()
    cli.main()